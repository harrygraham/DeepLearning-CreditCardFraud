{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "Here we walk through some data exploration and do work on our baseline models.\n",
    "\n",
    "The outline is as follows:\n",
    "\n",
    "* Look at data and run simple logistic regression classifer on data\n",
    "* Try resampling methods using this classifer \n",
    "* Implement other baseline classifiers using the best resampling technique \n",
    "* See briefly what tuning can be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imports and printing utility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    " {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "   .output_png vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that prints a nice plot of the confusion matrix, that'll be useful to use later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the features have been normalised, except Time and Amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8f2b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print a plot of class balance\n",
    "classes = pd.value_counts(data['Class'], sort=True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.show()\n",
    "print classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the Amount column and drop the Time column and the old Amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>norm_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...            V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...      -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...      -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...       0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...      -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...      -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  norm_Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0     0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0    -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0     1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0     0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0    -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise and reshape the Amount column, so it's values lie between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data['norm_Amount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1,1))\n",
    "\n",
    "# Drop the old Amount column and also the Time column as we don't want to include this at this stage\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic regression (without sampling)\n",
    "---\n",
    "Let's setup a logistic regression classifier to run on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and classifer instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data to x and y and perform a train-test split on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we perform cross validation\n",
    "The reason we do this is so we compute an average of runs of our classifier, to be confident in it's results. The scoring metric here is defined as F1 as this is the metric we are most interested in. If you wanted the whole confusion matrix metrics performed under cross-val then you would need to essentially run cross-val yourself, looping over iterations and storing the matrix results. For the purposes of this, we'll just look at F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7184466   0.76829268  0.58333333  0.77011494  0.64516129]\n",
      "F1 mean =  0.697069770211\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "scores = cross_val_score(lr, X, y, scoring='f1', cv=5)\n",
    "print scores\n",
    "print 'F1 mean = ', np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data in a single run and print a confusion matrix\n",
    "This is just a single run for the purposes of printing a confusion matrix to give us a visualisation of how the classifer performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XucV1W9//HXe0AQvAGiZKAHKrzS\nAQGBtMwyEcyE+qWBlmgkldo53U5peSIzy+pUal46miTYOaJdFFKUiLTSIwp4x+uoqeAFEcW7iH5+\nf+w1+nWa73e+A989e+Y772eP/Zi911577bXBPqxZe+21FBGYmVk+GoqugJlZPXOQNTPLkYOsmVmO\nHGTNzHLkIGtmliMHWTOzHDnIdjGSekn6o6R1kn67CeUcIelPtaxbUSR9QNK9RdfD6pM8TrZjknQ4\n8FVgV+B54Fbg1Ii4bhPL/QzwJWDviNiwyRXt4CQFMDQiGouui3VNbsl2QJK+CpwO/AAYAOwEnANM\nqkHx/wLc1xUCbDUkdS+6DlbnIsJbB9qAbYAXgEMr5OlJFoQfS9vpQM90bj9gJfA1YDXwOHB0Oncy\nsB54Ld1jOvBd4DclZQ8GAuiejo8CHiRrTT8EHFGSfl3JdXsDS4F16efeJeeuBU4Brk/l/AnoX+bZ\nmur/jZL6TwYOAu4D1gLfKsk/BrgBeDblPQvokc79LT3Li+l5P1VS/jeBJ4CLmtLSNe9O9xiZjt8J\nPAXsV/R/G9465+aWbMfzPmBz4LIKeb4NjANGAMPJAs1JJeffQRasB5IF0rMl9Y2ImWSt40siYsuI\nuKBSRSRtAZwJTIyIrcgC6a0t5OsHXJnybgv8DLhS0rYl2Q4Hjga2B3oAX69w63eQ/RkMBL4DnA98\nGhgFfAD4T0lDUt7Xga8A/cn+7PYHjgWIiH1TnuHpeS8pKb8fWat+RumNI+IBsgD8G0m9gV8DsyPi\n2gr1NSvLQbbj2RZYE5V/nT8C+F5ErI6Ip8haqJ8pOf9aOv9aRCwga8XtspH1eQMYJqlXRDweESta\nyPNR4P6IuCgiNkTExcA9wMdK8vw6Iu6LiJeBS8n+gSjnNbL+59eAuWQB9IyIeD7d/y6yf1yIiOUR\nsSTd9x/AfwMfrOKZZkbEq6k+bxMR5wONwI3ADmT/qJltFAfZjudpoH8rfYXvBB4uOX44pb1ZRrMg\n/RKwZVsrEhEvkv2K/QXgcUlXStq1ivo01WlgyfETbajP0xHxetpvCoJPlpx/uel6STtLukLSE5Ke\nI2up969QNsBTEfFKK3nOB4YBv4iIV1vJa1aWg2zHcwPwKlk/ZDmPkf2q22SnlLYxXgR6lxy/o/Rk\nRCyMiAPIWnT3kAWf1urTVKdVG1mntjiXrF5DI2Jr4FuAWrmm4pAaSVuS9XNfAHw3dYeYbRQH2Q4m\nItaR9UOeLWmypN6SNpM0UdKPU7aLgZMkbSepf8r/m4285a3AvpJ2krQNcGLTCUkDJE1KfbOvknU7\nvNFCGQuAnSUdLqm7pE8BuwNXbGSd2mIr4DnghdTK/mKz808C72pjmWcAyyLic2R9zb/c5Fpal+Ug\n2wFFxE/JxsieRPZm+1HgeODylOX7wDLgduAO4OaUtjH3WgRckspaztsDY0Oqx2Nkb9w/yD8HMSLi\naeBgshENT5ONDDg4ItZsTJ3a6OtkL9WeJ2tlX9Ls/HeB2ZKelXRYa4VJmgRM4K3n/CowUtIRNaux\ndSn+GMHMLEduyZqZ5chB1swsRw6yZmY5cpA1M8tRh5ocQ917hXpsVXQ1rIb23G2noqtgNfTww/9g\nzZo1rY1Drlq3rf8lYsM/fXRXVrz81MKImFCr+7eHjhVke2xFz11aHWVjncj1N55VdBWshvYZO7qm\n5cWGl9v0//lXbj27ta/5OpwOFWTNrKsRqL57LR1kzaw4AlSz3ocOyUHWzIrllqyZWV4EDd2KrkSu\nHGTNrFjuLjAzy4lwd4GZWX7klqyZWa7ckjUzy5FbsmZmean/jxHq++nMrGNr+hih2q2aIqWvSFoh\n6U5JF0vaXNIQSTdKapR0iaQeKW/PdNyYzg8uKefElH6vpANL0iektEZJJ7RWHwdZMyuWGqrfWitK\nGgj8GzA6IoYB3YApwI+An0fEe4BngOnpkunAMyn95ykfknZP1+1BthzROZK6SeoGnA1MJFvHbmrK\nW5aDrJkVSDUNskl3oJek7mQrMT8OfBj4XTo/m7dWg56Ujknn95eklD43Il6NiIeARmBM2hoj4sGI\nWA/MTXnLcpA1s+II6Nat+g36S1pWss0oLS4iVgH/BTxCFlzXkS0Q+mxEbEjZVgID0/5AsoVKSefX\nAduWpje7plx6WX7xZWbFatvogjURUXa+RUl9yVqWQ4Bngd+S/bpfGAdZMytQzUcXfAR4KCKeApD0\nB2AfoI+k7qm1OghYlfKvAnYEVqbuhW3IlrVvSm9Sek259Ba5u8DMilXb0QWPAOMk9U59q/sDdwHX\nAJ9MeaYB89L+/HRMOv+XiIiUPiWNPhgCDAVuApYCQ9NohR5kL8fmV6qQW7JmVqwatmQj4kZJvwNu\nBjYAtwDnAVcCcyV9P6VdkC65ALhIUiOwlixoEhErJF1KFqA3AMdFxOsAko4HFpKNXJgVESsq1clB\n1syK04bxr9WKiJnAzGbJD5KNDGie9xXg0DLlnAqc2kL6AmBBtfVxkDWzYtX5F18OsmZWLM9dYGaW\nl/qfu8BB1syK5ZasmVlOvDKCmVmevJCimVm+3JI1M8uR+2TNzHIijy4wM8uXW7JmZvmRg6yZWT6y\nJb4cZM3M8qG01TEHWTMrkNySNTPLk4OsmVmOGho8hMvMLB/ukzUzy4+6QJ9sfbfTzazDk1T1VkVZ\nu0i6tWR7TtKXJfWTtEjS/eln35Rfks6U1CjpdkkjS8qalvLfL2laSfooSXeka85UKxVzkDWzQtUy\nyEbEvRExIiJGAKOAl4DLgBOAxRExFFicjgEmkq1EOxSYAZyb6tSPbJ2wsWRrg81sCswpzzEl102o\nVCcHWTMrVC2DbDP7Aw9ExMPAJGB2Sp8NTE77k4A5kVkC9JG0A3AgsCgi1kbEM8AiYEI6t3VELElL\nh88pKatF7pM1s+K0/cVXf0nLSo7Pi4jzyuSdAlyc9gdExONp/wlgQNofCDxacs3KlFYpfWUL6WU5\nyJpZodrYQl0TEaOrKLMHcAhwYvNzERGSoi033RTuLjCzwjSNLsihu2AicHNEPJmOn0y/6pN+rk7p\nq4AdS64blNIqpQ9qIb0sB1kzK1ROQXYqb3UVAMwHmkYITAPmlaQfmUYZjAPWpW6FhcB4SX3TC6/x\nwMJ07jlJ49KogiNLymqRuwvMrDgCNdR2nKykLYADgM+XJJ8GXCppOvAwcFhKXwAcBDSSjUQ4GiAi\n1ko6BVia8n0vItam/WOBC4FewFVpK8tB1swKVeuPESLiRWDbZmlPk402aJ43gOPKlDMLmNVC+jJg\nWLX1cZA1s0LV+xdfDrJmVpiu8Fmtg6yZFau+Y6yDrJkVSO4usAq+dMSHOOrjexMRrGh8jBkzf8Mv\nvj2FD4x6D+teeAWAGd+5iNvvW8WUiaP56lEHIIkXXnqFf/vBJdxx36qy5by6fsOb9/npNz7JkZPe\nx3b7fK2Q57S3fP5zn+WqBVew3fbbs/zWOwE48Zv/wYIr/0iPzXow5N3v5rxf/Zo+ffoUXNPOo96D\nrMfJbqR3brcNx079IPsc8WNGH/oDujU0cOiBowD41umXM27KaYybchq3p0D6j8eeZvznTmevw37A\nD8+/mrNPmtpqOQAjd9+JPlv1bv8HtBZ9ZtpRzLvi6rel7f+RA1h+650sveV2hg7dmZ/86IcF1a5z\nynHugg7BQXYTdO/WjV49N6NbtwZ6bd6Dx59aVzbvktse4tnnXwbgptsfYuCAt1o65cppaBA/+PJk\nvn3G5fk+iFXt/R/Yl379+r0t7SMHjKd79+yXwjFjx7Fq5cqWLrVy1IatE3KQ3UiPPbWO0+cs5r6r\nTuGhRafy3Asvs3jJPQB897iPcdMlJ/Ljr32CHpv9c4/MUZP3ZuH1d7Vazhc/9UGu/OsdPLHmufZ7\nMNskcy6cxYETJhZdjU7FLdlNIGmCpHvT5LYntH5F59Fnq14cvN972e3gmbxr/LfZolcPphy0F9/5\nxXyGf/wU3v/pn9B3my342tEfedt1+44eyrTJ7+OkM+ZVLGeH7bbhEwfsyTlz/1rE49lG+NEPT6Vb\n9+5MOfyIoqvSabQlwDrINiOpG3A22UQNuwNTJe2e1/3a24fH7so/HnuaNc+8wIYNb3D5X25j3PAh\nb7Y617+2gTnzljB6j8FvXjNs6Ds59zuHc+hXzmPtuhcrljN8l0G8a8ftWDF/JvdceTK9N9+MO+fN\nLOJRrQoXzb6QBVdewYVz/qfTBoOiNDQ0VL11RnmOLhgDNEbEgwCS5pJNkHtXjvdsN48+sZYx7x1C\nr8034+VXXuNDY3bh5rse4R39t34z0B7yoX/lrgceA2DHd/Rl7n8dw/T/nEPjI6tbLefq61Yw5IBv\nvZnvqet/yrBJJ7fvQ1pV/rTwan720x/zp8V/pXdvv6Rsszr/NynPINvSpLdjm2eSNINs2QfYbMsc\nq1NbS+98mMv+fAs3/O832fD6G9x2z0ou+P31zDvri/TvuxUS3H7vSr506lwATpwxkX59tuD0Ez8F\nwIbX3+D9R/y4bDnWMR356an8/a/XsmbNGt49eBD/+Z2T+cmPf8irr77KwRMOALKXX78455cF17Tz\nqPeWv7L5EXIoWPokMCEiPpeOPwOMjYjjy13T0Hv76LnLYeVOWyf0zNKziq6C1dA+Y0ezfPmymkXF\nnu8YGoOOOLPq/A/+7KDl1Uza3ZHk2ZItN+mtmRmQRmbVd0M219EFS4GhkoakpSCmkE2Qa2aW1P/o\ngtxashGxQdLxZDOMdwNmRcSKvO5nZp1TJ42dVct17oKIWEA287iZWYs6awu1Wp4gxsyKo/pvyXbO\n0b1mVhdENkdHtVtVZUp9JP1O0j2S7pb0Pkn9JC2SdH/62TfllaQz01ept0saWVLOtJT/fknTStJH\nSbojXXOmWmmKO8iaWaFqHWSBM4CrI2JXYDhwN3ACsDgihgKL0zFkX6QOTdsM4FwASf2AmWRj+8cA\nM5sCc8pzTMl1Eyo+X7W1NjOrudRdUO3WanHSNsC+wAUAEbE+Ip4l+9p0dso2G5ic9icBcyKzBOgj\naQfgQGBRRKyNiGeARcCEdG7riFiSFmGcU1JWixxkzaww2TjZmg7hGgI8Bfxa0i2SfpWWCB8QEY+n\nPE8AA9J+S1+mDmwlfWUL6WU5yJpZgdo8Tra/pGUl24xmBXYHRgLnRsSewIu81TUAvLkMeD6furbA\nowvMrFBtHF2wppXPalcCKyPixnT8O7Ig+6SkHSLi8fQrf9MsTeW+TF0F7Ncs/dqUPqiF/GW5JWtm\nhapld0FEPAE8KmmXlLQ/2cx/84GmEQLTgHlpfz5wZBplMA5Yl7oVFgLjJfVNL7zGAwvTueckjUuj\nCo4sKatFbsmaWXHyGSf7JeB/0uf8DwJHkzUoL5U0HXgYaJqJagFwENAIvJTyEhFrJZ1CNj0AwPci\nYm3aPxa4EOgFXJW2shxkzawwTS++aikibgVa6lLYv4W8ARxXppxZwKwW0pcBw6qtj4OsmRWq3r/4\ncpA1s0J57gIzs7yItnzJ1Sk5yJpZYbrCpN0OsmZWoM47GXe1HGTNrFB1HmMdZM2sWG7JmpnlpQtM\n2u0ga2aFyeNjhI7GQdbMCuUga2aWozqPsQ6yZlYst2TNzPLiF19mZvkRbVogsVNykDWzQjXUeVPW\nQdbMClXnMdZB1syKky31Xd9R1kHWzApV512yDrJmVqx6b8mWXa1W0taVtvaspJnVL6n6rbry9A9J\nd0i6VdKylNZP0iJJ96effVO6JJ0pqVHS7ZJGlpQzLeW/X9K0kvRRqfzGdG3FmlVqya4Aguzz4iZN\nxwHsVN0jm5m1TGTDuHLwoYhYU3J8ArA4Ik6TdEI6/iYwERiatrHAucBYSf2AmWQLMgawXNL8iHgm\n5TkGuJFstdsJVFixtmyQjYgdN/75zMyq0059spOA/dL+bOBasiA7CZiTVq1dIqmPpB1S3kVNy4BL\nWgRMkHQtsHVELEnpc4DJVAiyZbsLSkmaIulbaX+QpFFtfEAzs3+mbGWEajegv6RlJduMFkoN4E+S\nlpecHxARj6f9J4ABaX8g8GjJtStTWqX0lS2kl9Xqiy9JZwGbAfsCPwBeAn4J7NXatWZmlQjo1ram\n7JqIGN1KnvdHxCpJ2wOLJN1TejIiQlK0saobrZqW7N4R8XngFYDUfO6Ra63MrMuo9YuviFiVfq4G\nLgPGAE+mbgDSz9Up+yqgtGt0UEqrlD6ohfSyqgmyr0lqIGuCI2lb4I0qrjMza1UbuwtaK2sLSVs1\n7QPjgTuB+UDTCIFpwLy0Px84Mo0yGAesS90KC4HxkvqmkQjjgYXp3HOSxqVRBUeWlNWiasbJng38\nHthO0snAYcDJVVxnZlZRW1qoVRoAXJYCcnfgfyPiaklLgUslTQceJotjkI0OOAhoJOsKPRqy39gl\nnQIsTfm+1/QSDDgWuBDoRfbCq+xLr6ZKVBQRcyQtBz6Skg6NiDtbf1Yzs9bVcoKYiHgQGN5C+tPA\n/i2kB3BcmbJmAbNaSF8GDKu2TtV+8dUNeI2sy6CqEQlmZtWo7++9qgiYkr4NXAy8k6yT938lnZh3\nxcysa6hln2xHVE1L9khgz4h4CUDSqcAtwA/zrJiZ1T/hCWIAHm+Wr3tKMzPbNJ24hVqtskFW0s/J\n+mDXAiskLUzH43nrjZuZ2Sap8xhbsSXbNIJgBXBlSfqS/KpjZl3JRnzx1elUmiDmgvasiJl1TV22\nu6CJpHcDpwK7A5s3pUfEzjnWy8y6iPoOsdWNeb0Q+DXZn8VE4FLgkhzrZGZdhJR9jFDt1hlVE2R7\nR8RCgIh4ICJOIgu2ZmabrNYTxHQ01QzhejVNEPOApC+QzTizVb7VMrOuosv3yQJfAbYA/o2sb3Yb\n4LN5VsrMuo46j7FVTRBzY9p9HvhMvtUxs65EdN6+1mpV+hjhMtIcsi2JiE/kUiMz6zo6cV9rtSq1\nZM9qt1oke+62E9ff2O63NbMCddk+2YhY3J4VMbOuqd7nTq12Plkzs5rr0p/Vmpm1hzqPsdW31CX1\nzLMiZtb1ZB8Z1H7SbkndJN0i6Yp0PETSjZIaJV0iqUdK75mOG9P5wSVlnJjS75V0YEn6hJTWKOmE\n1upSzcoIYyTdAdyfjodL+kXVT2tmVkGDqt/a4N+Bu0uOfwT8PCLeAzwDTE/p04FnUvrPUz4k7Q5M\nAfYAJgDnpMDdjWxx2Ylk87lMTXnLP18VlT0TOBh4GiAibgM+VMV1ZmatqvVntZIGAR8FfpWOBXwY\n+F3KMhuYnPYnpWPS+f1T/knA3Ih4NSIeIlvNdkzaGiPiwYhYD8xNecuqpk+2ISIebtZUf72K68zM\nKsqWn2lTE7W/pGUlx+dFxHnN8pwOfIO3Pv/fFng2Ijak45XAwLQ/EHgUICI2SFqX8g/k7XNnl17z\naLP0sZUqXE2QfVTSGCBSU/lLwH1VXGdm1qo2DuFaExGjy52UdDCwOiKWS9pv02pWG9UE2S+SdRns\nBDwJ/DmlmZltshp/i7APcIikg8jmv94aOAPoI6l7as0OIpvoivRzR2ClpO5kc7M8XZLepPSacukt\navUfkYhYHRFTIqJ/2qZExJrWrjMza43aMJdsNd0KEXFiRAyKiMFkL67+EhFHANcAn0zZpgHz0v78\ndEw6/5eIiJQ+JY0+GAIMBW4iW99waBqt0CPdY36lOlWzMsL5tDCHQUTMaO1aM7PWtNNXtd8E5kr6\nPnAL0LS81gXARZIayRaNnQIQESskXQrcBWwAjouI17P66nhgIdANmBURKyrduJrugj+X7G8OfJy3\nd/yamW0UAd1z+hohIq4Frk37D5KNDGie5xXg0DLXn0o2vWvz9AXAgmrrUc1Uh29bakbSRcB11d7A\nzKySOp8fZqM+qx0CDKh1RcysC2r7RwadTjV9ss/wVp9sA1m/RaufkpmZVUN1vl5txSCbvnwYzltD\nFN5Ib97MzDZZ9jFC0bXIV8UhXCmgLoiI19PmAGtmNZXT3AUdRjUfW9wqac/ca2JmXVIes3B1JJXW\n+Gr6OmJPYKmkB4AXyVr4EREj26mOZlanukJ3QaU+2ZuAkcAh7VQXM+tquvhCigKIiAfaqS5m1gV1\n2SXBge0kfbXcyYj4WQ71MbMuJFvjq+ha5KtSkO0GbAl1PojNzAokGuo8xFQKso9HxPfarSZm1uUI\n98mameWnE49/rValILt/u9XCzLqsLvviKyLWtmdFzKzr6erdBWZmueuyLVkzs/ZQ5zHWQdbMiiPa\nvFptp+Mga2bFEZ124pdq1fs/ImbWwakNW6tlSZtLuknSbZJWSDo5pQ+RdKOkRkmXpJVmSavRXpLS\nb5Q0uKSsE1P6vZIOLEmfkNIaJbW6gIGDrJkVRkA3qeqtCq8CH46I4cAIYIKkccCPgJ9HxHuAZ4Dp\nKf904JmU/vOUD0m7k61cuwcwAThHUjdJ3YCzgYnA7sDUlLcsB1kzK5RU/daayLyQDjdLWwAfBn6X\n0mcDk9P+pHRMOr9/WhFmEjA3Il6NiIeARrLVbscAjRHxYESsB+amvGU5yJpZgaqfsDv13faXtKxk\nm/FPJWYtzluB1cAi4AHg2TQ/NsBKYGDaHwg8CpDOrwO2LU1vdk259LL84svMCrMRowvWRMToShki\n4nVghKQ+wGXArhtbv1pwkDWzQuU1uiAinpV0DfA+oE/Jai+DeGtx2FXAjsBKSd2BbYCnS9KblF5T\nLr1F7i4ws0LVeHTBdqkFi6RewAHA3cA1wCdTtmnAvLQ/Px2Tzv8lLRg7H5iSRh8MAYaSrRazFBia\nRiv0IHs5Nr9SndySNbPi1H6c7A7A7DQKoAG4NCKukHQXMFfS94FbgAtS/guAiyQ1AmvJgiYRsULS\npcBdwAbguNQNgaTjgYVkc27PiogVlSrkIGtmhan1F18RcTvZ4q/N0x8kGxnQPP0V4NAyZZ0KnNpC\n+gJgQbV1cpA1s0LV+xdfDrJmVqj6DrEOsmZWoKYvvuqZg6yZFarOY6yDrJkVSajOOwwcZM2sUG7J\nmpnlJBvCVd9R1kHWzIpT5exanZmDrJkVykHWzCxH9f7iyxPE5GyX9wxm9Ij3MnbUCPYZ+9YMbeec\n9QuGD9uVkcP34FsnfKPAGlpbnXXmGYwaMYyRw/fgF2ecDsDvf/dbRg7fg949Gli+bFnBNew8BDSo\n+q0zcku2HVz952vo37//m8d/vfYarvjjPG5afhs9e/Zk9erVBdbO2mLFnXfy61nn8/f/u4kePXpw\nyEcncNBHD2aPPYYx99I/cPyxny+6ip2OW7JWc+f997l8/Rsn0LNnTwC23377gmtk1brnnrvZa6+x\n9O7dm+7du/OBfT/I5Zf/gV13242dd9ml6Op1Sg1S1Vtn5CCbM0l8bOJ49h4zigvOPw+Axvvu4/rr\n/s4H9h7LAR/+IMuWLi24llatPfYYxvXX/52nn36al156iauvWsDKRx9t/UJrkbsLNoGkWcDBwOqI\nGJbXfTq6xddex8CBA1m9ejUHTziAXXbdlQ2vb2Dt2rX87folLFu6lE8ffhh33/dg3c9GVA923W03\nvvb1b/KxiePpvcUWDB8+gm7duhVdrU6s/r/4yrMleyHZUrpd2sCB2Rpr22+/PYdM/jhLl97EwIGD\nmPzxTyCJvcaMoaGhgTVr1hRcU6vWUZ+dzv/dtJw/X/M3+vTty9ChOxddpc6rDSvVdtY2SG5BNiL+\nRjbTeJf14osv8vzzz7+5/+dFf2KPPYbxsUMm89drrwHg/vvuY/369W97MWYdW9OLykceeYR5l/+B\nT009vOAadW61XH6mIyp8dEFa0ncGwI477VRwbWpr9ZNP8qlPfhyADa9v4FNTDmf8gRNYv349n//c\nZxk1Yhg9NuvBr2bNdldBJzL1sP/H2rVPs1n3zTj9zLPp06cP8y6/jK9++UuseeopPjHpo/zr8BH8\nccHCoqva4WV9svX9376yNcNyKlwaDFxRbZ/sqFGj4/obPcbQrKPaZ+xoli9fVrOouNt794xfX3ZN\n1fnfN7Tv8kpLgkvaEZgDDAACOC8izpDUD7gEGAz8AzgsIp5R1ro5AzgIeAk4KiJuTmVNA05KRX8/\nIman9FFk3aG9yJah+feoEEg9usDMilXb/oINwNciYndgHHCcpN2BE4DFETEUWJyOASaSrUQ7lOw3\n6nMBUlCeCYwlWxtspqS+6ZpzgWNKrqv47slB1swKpTb8rzUR8XhTSzQinidbDnwgMAmYnbLNBian\n/UnAnMgsAfpI2gE4EFgUEWsj4hlgETAhnds6Ipak1uuckrJalFuQlXQxcAOwi6SVkqbndS8z67za\nOLqgv6RlJduM8uVqMNnKtTcCAyLi8XTqCbLuBMgCcOlA55UprVL6yhbSy8rtxVdETM2rbDOrH23s\n4F1TqU/2zTKlLYHfA1+OiOdKXyxHREjK72VUM+4uMLPCiOyryGq3qsqUNiMLsP8TEX9IyU+mX/VJ\nP5smDFkF7Fhy+aCUVil9UAvpZTnImllxavwxQhotcAFwd0T8rOTUfGBa2p8GzCtJP1KZccC61K2w\nEBgvqW964TUeWJjOPSdpXLrXkSVltajwcbJm1rXVeJTsPsBngDsk3ZrSvgWcBlya3g09DByWzi0g\nG77VSDaE62iAiFgr6RSgaWKR70VE08dVx/LWEK6r0laWg6yZFauGUTYirqtQ4v4t5A/guDJlzQJm\ntZC+DKh6PhYHWTMrUP1PEOMga2aFqvOvah1kzaw4nXnil2o5yJpZseo8yjrImlmh3CdrZpYj98ma\nmeWlE694UC0HWTMrlLsLzMxyks1dUHQt8uUga2aFqvMY6yBrZgWr8yjrIGtmhXKfrJlZjtwna2aW\nozqPsQ6yZlawOo+yDrJmVphsgpj6jrIOsmZWHEFDfcdYB1kzK1idB1kvpGhmBVKb/tdqadIsSasl\n3VmS1k/SIkn3p599U7oknSl7+SoGAAAGg0lEQVSpUdLtkkaWXDMt5b9f0rSS9FGS7kjXnKkqltB1\nkDWzQtVytVqyBQ4nNEs7AVgcEUOBxekYYCIwNG0zgHOz+qgfMBMYC4wBZjYF5pTnmJLrmt/rnzjI\nmllh1MatNRHxN2Bts+RJwOy0PxuYXJI+JzJLgD6SdgAOBBZFxNqIeAZYBExI57aOiCVpAcY5JWWV\n5T5ZMytW2/pk+0taVnJ8XkSc18o1AyLi8bT/BDAg7Q8EHi3JtzKlVUpf2UJ6RQ6yZlaoNg7hWhMR\nozf2XhERkmJjr98Y7i4ws0LVuE+2JU+mX/VJP1en9FXAjiX5BqW0SumDWkivyEHWzApVyz7ZMuYD\nTSMEpgHzStKPTKMMxgHrUrfCQmC8pL7phdd4YGE695ykcWlUwZElZZXl7gIzK06Nl5+RdDGwH1nf\n7UqyUQKnAZdKmg48DByWsi8ADgIagZeAowEiYq2kU4ClKd/3IqLpZdqxZCMYegFXpa0iB1kzK1jt\nomxETC1zav8W8gZwXJlyZgGzWkhfBgxrS50cZM2sMMKf1ZqZ5crzyZqZ5cizcJmZ5am+Y6yDrJkV\nq85jrIOsmRVnEz8y6BQcZM2sUO6TNTPLU33HWAdZMytWncdYB1kzK5b7ZM3MciJEQ51HWc/CZWaW\nI7dkzaxQdd6QdZA1s2J5CJeZWV78MYKZWX42ccWDTsFB1syKVedR1kHWzArlPlkzsxy5T9bMLEd1\nHmMdZM2sWKrzpqyDrJkVRtR/d4GyVXE7BklPka2LXu/6A2uKroTVVFf5O/2XiNiuVoVJuprsz65a\nayJiQq3u3x46VJDtKiQti4jRRdfDasd/p1aOJ4gxM8uRg6yZWY4cZItxXtEVsJrz36m1yH2yZmY5\nckvWzCxHDrJmZjlykG1HkiZIuldSo6QTiq6PbTpJsyStlnRn0XWxjslBtp1I6gacDUwEdgemStq9\n2FpZDVwIdKrB8da+HGTbzxigMSIejIj1wFxgUsF1sk0UEX8D1hZdD+u4HGTbz0Dg0ZLjlSnNzOqY\ng6yZWY4cZNvPKmDHkuNBKc3M6piDbPtZCgyVNERSD2AKML/gOplZzhxk20lEbACOBxYCdwOXRsSK\nYmtlm0rSxcANwC6SVkqaXnSdrGPxZ7VmZjlyS9bMLEcOsmZmOXKQNTPLkYOsmVmOHGTNzHLkIFtH\nJL0u6VZJd0r6raTem1DWfpKuSPuHVJo1TFIfScduxD2+K+nr1aY3y3OhpE+24V6DPVOWFcFBtr68\nHBEjImIYsB74QulJZdr8dx4R8yPitApZ+gBtDrJmXYGDbP36O/Ce1IK7V9Ic4E5gR0njJd0g6ebU\n4t0S3pzv9h5JNwOfaCpI0lGSzkr7AyRdJum2tO0NnAa8O7Wif5Ly/YekpZJul3RySVnflnSfpOuA\nXVp7CEnHpHJuk/T7Zq3zj0halso7OOXvJuknJff+/Kb+QZptCgfZOiSpO9m8tXekpKHAORGxB/Ai\ncBLwkYgYCSwDvippc+B84GPAKOAdZYo/E/hrRAwHRgIrgBOAB1Ir+j8kjU/3HAOMAEZJ2lfSKLLP\niUcABwF7VfE4f4iIvdL97gZKv6ganO7xUeCX6RmmA+siYq9U/jGShlRxH7NcdC+6AlZTvSTdmvb/\nDlwAvBN4OCKWpPRxZJOGXy8JoAfZZ6G7Ag9FxP0Akn4DzGjhHh8GjgSIiNeBdZL6NsszPm23pOMt\nyYLuVsBlEfFSukc1czcMk/R9si6JLck+S25yaUS8Adwv6cH0DOOBfy3pr90m3fu+Ku5lVnMOsvXl\n5YgYUZqQAumLpUnAooiY2izf267bRAJ+GBH/3eweX96Isi4EJkfEbZKOAvYrOdf8m/BI9/5SRJQG\nYyQN3oh7m20ydxd0PUuAfSS9B0DSFpJ2Bu4BBkt6d8o3tcz1i4Evpmu7SdoGeJ6sldpkIfDZkr7e\ngZK2B/4GTJbUS9JWZF0TrdkKeFzSZsARzc4dKqkh1fldwL3p3l9M+ZG0s6QtqriPWS7cku1iIuKp\n1CK8WFLPlHxSRNwnaQZwpaSXyLobtmqhiH8HzkuzTb0OfDEibpB0fRoidVXql90NuCG1pF8APh0R\nN0u6BLgNWE02/WNr/hO4EXgq/Syt0yPATcDWwBci4hVJvyLrq71Z2c2fAiZX96djVnuehcvMLEfu\nLjAzy5GDrJlZjhxkzcxy5CBrZpYjB1kzsxw5yJqZ5chB1swsR/8ff9lUU1U5jUkAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116158d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.88      0.62      0.73       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation\n",
    "\n",
    "So, as we can see, without any sampling techniques on the data, running a simple logistic regression gives us a F1 score average of around 73%. \n",
    "\n",
    "This is not great. That means that nearly 40% of fraudlent cases were incorrectly predicted. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aside on C parameter of Logistic regression\n",
    "---\n",
    "The C parameter of the logistic regression is essentially a regularisation parameter. Increasing the regularisation strength penalises \"large\" weight coefficients. This is mainly so that the model performs better on unseen data and avoids learning anomolies or noise.\n",
    "\n",
    "#### To determine the best value to give this parameter we can do a quick hyper-parameter tuning, namely Grid Search, to find the best value to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.695 (+/-0.112) for {'C': 0.01}\n",
      "0.717 (+/-0.077) for {'C': 0.1}\n",
      "0.725 (+/-0.072) for {'C': 1}\n",
      "0.727 (+/-0.085) for {'C': 10}\n",
      "0.727 (+/-0.085) for {'C': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.88      0.62      0.73       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = GridSearchCV(LogisticRegression(C = 0.01), {'C':[0.01, 0.1, 1, 10, 100]}, scoring='f1')\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "# # Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# class_names = [0,1]\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print \"\"\n",
    "print(lr.best_params_)\n",
    "print \"\"\n",
    "print(\"Grid scores on development set:\")\n",
    "print \"\"\n",
    "means = lr.cv_results_['mean_test_score']\n",
    "stds = lr.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lr.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print \"\"\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print \"\"\n",
    "print classification_report(y_test, y_pred)\n",
    "print \"\"\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we can see here that C=10 is the best value to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Undersampling \n",
    "---\n",
    "#### Here, we will attempt undersampling by reducing the number of the majority class, down to a 50:50 ratio with the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "[ 0.90526316  0.9375      0.90810811  0.95789474  0.91005291]\n",
      "F1 mean =  0.92376378258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxxjNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d61510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       147\n",
      "          1       0.95      0.92      0.94       149\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "print 'Number of frauds', len(fraud_indices)\n",
    "\n",
    "non_fraud = data[data.Class==0]\n",
    "fraud = data[data.Class==1]\n",
    "\n",
    "print 'number of non fraud: ', len(non_fraud)\n",
    "non_fraud = non_fraud.loc[np.random.choice(non_fraud.index, len(fraud_indices), replace=False)]\n",
    "\n",
    "undersampled_data = pd.concat([non_fraud, fraud])\n",
    "print 'non_fraud after: ', len(non_fraud)\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10)\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = undersampled_data.ix[:, data.columns != 'Class']\n",
    "y = undersampled_data.ix[:, data.columns == 'Class']\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "# CROSS VALIDATION\n",
    "scores = cross_val_score(lr, X, y, scoring='f1', cv=5)\n",
    "print scores\n",
    "print 'F1 mean = ', np.mean(scores)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### As we can see, by bringing the data to a 50:50 ratio, we bring the recall performance up to 88% average! up from 60%.\n",
    "This is a significant increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Oversampling \n",
    "---\n",
    "\n",
    "Next, we want to try oversampling techniques. This is where the minority class (the fraudulent cases) is scaled up in size, to compare more equally with the number of the majority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A way we can do this is by random oversampling, which randomly duplicates data. Let's see how this performs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Resampled training dataset shape Counter({0: 284315, 1: 284315})\n",
      "[ 0.7184466   0.76829268  0.58333333  0.77011494  0.64516129]\n",
      "F1 mean =  0.697069770211\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na2ZWQg6yZmYl5CBrZlZC/x/VFcpcD3hz3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11327b950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95     85172\n",
      "          1       0.98      0.92      0.95     85417\n",
      "\n",
      "avg / total       0.95      0.95      0.95    170589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "# Setup oversampler and print new data shape\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_res, y_res = ros.fit_sample(X, y)\n",
    "print('Original dataset shape {}'.format(Counter(data['Class'])))\n",
    "print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size = 0.3, random_state = 0)\n",
    "\n",
    "# CROSS VALIDATION - NOW ONLY ON TRAINING DATA *\n",
    "scores = cross_val_score(lr, X, y, scoring='f1', cv=5)\n",
    "print scores\n",
    "print 'F1 mean = ', np.mean(scores)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### Oversampling definitely seems to perform slightly better than undersampling here.  We bring the recall performance up to 92% average, fairly conclusively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: However we have to think whether this is wise. Simply duplicating data means that model has potential to cheat. Some of the test data in the test-train split will be the same data as in training. This means that there is likely to be some bias in predictions. \n",
    "\n",
    "#### How to overcome? - Instead of oversampling straight away, we should SPLIT the data into test-train FIRST and THEN apply oversampling. This means we have less test data but it is TRUE test data that has not been seen before by the model. \n",
    "\n",
    "#### Let's retry this random oversampling but sampling ONLY the training data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Oversampling ( Preserving test data - oversampling training data only)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code will look almost identical to before, just a shift in the order of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swap the order of data splitting and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199019, 1: 345})\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n"
     ]
    }
   ],
   "source": [
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_res, y_res = ros.fit_sample(X_train, y_train)\n",
    "print('Original dataset shape {}'.format(Counter(data['Class'])))\n",
    "print('Training dataset shape {}'.format(Counter(y_train['Class'])))\n",
    "print('Resampled training dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we see, the shape of the data is an equal, but less than 284315 split. This is because we are resampling the TRAINING data only. This then leaves 147 fraud cases for testing, as seen in the confusion matric results below.\n",
    "\n",
    "EXTENSION: Experiment with variations on fraud test data. I.e. Take a lower amount of fraud training data and oversample, leaving more 'True' fraud data for testing and see if there is any better performance.\n",
    "\n",
    "\n",
    "#### Then do as usual, cross validate and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.94351454  0.94433796  0.94443437  0.94459841  0.94653665]\n",
      "F1 mean =  0.944684384668\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFMCoh0F7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d6c5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     85296\n",
      "          1       0.06      0.91      0.12       147\n",
      "\n",
      "avg / total       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "scores = cross_val_score(lr, X_res, y_res, scoring='f1', cv=5)\n",
    "print scores\n",
    "print 'F1 mean = ', np.mean(scores)\n",
    "\n",
    "lr.fit(X_res, y_res)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### Oversampling on training data only seems to perform approximately the same, if not slightly less. This is to be expected however, as the hypothesis was that by oversampling the entire dataset, some of our duplicates were 'leaking' into our test sets which could have created some slight bias. \n",
    "\n",
    "#### So for the purposes of Oversampling by Random, duplication, I would conclude that moving forward with the second method is absolutely fine given the intuition and empirical result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SMOTE ( Preserving test data - oversampling training data only)\n",
    "---\n",
    "\n",
    "### Now we try the SMOTE method (Synthetic Minority Oversampling Technique). \n",
    "#### This will oversample our minority data in a similar fashion as before, except the new data will be synthetic ones, which means fraudulent data will be slightly modified (i.e noise added, tweak of value etc) to create new examples.\n",
    "\n",
    "#### The procedure is similar to before, sampling training data only to preserve test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 199013, 1: 199013})\n",
      "[ 0.94455464  0.94354421  0.94324048  0.94478639  0.94327122]\n",
      "F1 mean =  0.943879387236\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4b7e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.99     85302\n",
      "          1       0.06      0.91      0.11       141\n",
      "\n",
      "avg / total       1.00      0.97      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=1)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)\n",
    "print('Original dataset shape {}'.format(Counter(data['Class'])))\n",
    "print('Training dataset shape {}'.format(Counter(y_train['Class'])))\n",
    "print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "# CROSS VALIDATION\n",
    "scores = cross_val_score(lr, X_res, y_res, scoring='f1', cv=5)\n",
    "print scores\n",
    "print 'F1 mean = ', np.mean(scores)\n",
    "\n",
    "lr.fit(X_res, y_res)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### Oversampling on training data using SMOTE seems to perform approximately the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(x_data, y_data):\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(x_data, y_data)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_2(X, y, clf, n):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        print len(train_index)\n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        print len(y_train_folds[y_train_folds['Class']==1])\n",
    "        X_res, y_res = smote_data(X_train_folds, y_train_folds )\n",
    "        \n",
    "        \n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "227845\n",
      "393\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[1]\n",
      "227845\n",
      "393\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[2]\n",
      "227846\n",
      "394\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[3]\n",
      "227846\n",
      "394\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[4]\n",
      "227846\n",
      "394\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[5]\n",
      "('Mean scores: ', ['LogisticRegression', 0.11136541674423021, 0.05974964355476492, 0.8902082044939188, datetime.timedelta(0, 5, 947349)])\n",
      "['LogisticRegression', 0.11136541674423021, 0.05974964355476492, 0.8902082044939188, datetime.timedelta(0, 5, 947349)]\n",
      "F1 mean =  0.111365416744\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALIDATION\n",
    "scores = custom_cross_val_2(X, y,lr, 5)\n",
    "print scores\n",
    "print 'F1 mean = ', scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_data(x_data, y_data):\n",
    "\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_res, y_res = ros.fit_sample(x_data, y_data)\n",
    "    print('Original dataset shape {}'.format(Counter(data['Class'])))\n",
    "    print('Training dataset shape {}'.format(Counter(y_train['Class'])))\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_3(X, y, clf, n):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        print len(train_index)\n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        print len(y_train_folds[y_train_folds['Class']==1])\n",
    "        X_res, y_res = oversample_data(X_train_folds, y_train_folds )\n",
    "        \n",
    "        \n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "227845\n",
      "393\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[1]\n",
      "227845\n",
      "393\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[2]\n",
      "227846\n",
      "394\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[3]\n",
      "227846\n",
      "394\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[4]\n",
      "227846\n",
      "394\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 227452, 1: 227452})\n",
      "Fitting the model... CV[5]\n",
      "('Mean scores: ', ['LogisticRegression', 0.11623623449852916, 0.062614185797477295, 0.90032982890125746, datetime.timedelta(0, 5, 275111)])\n"
     ]
    }
   ],
   "source": [
    "scores = custom_cross_val_3(X, y, lr, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "256325\n",
      "442\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[1]\n",
      "256325\n",
      "442\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[2]\n",
      "256326\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[3]\n",
      "256326\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[4]\n",
      "256326\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[5]\n",
      "256327\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[6]\n",
      "256327\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[7]\n",
      "256327\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[8]\n",
      "256327\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[9]\n",
      "256327\n",
      "443\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[10]\n",
      "('Mean scores: ', ['LogisticRegression', 0.11092022946688154, 0.059684765875965239, 0.87628571428571433, datetime.timedelta(0, 6, 112225)])\n"
     ]
    }
   ],
   "source": [
    "scores = custom_cross_val_2(X, y,lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "256325\n",
      "442\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[1]\n",
      "256325\n",
      "442\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[2]\n",
      "256326\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[3]\n",
      "256326\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[4]\n",
      "256326\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255883, 1: 255883})\n",
      "Fitting the model... CV[5]\n",
      "256327\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[6]\n",
      "256327\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[7]\n",
      "256327\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[8]\n",
      "256327\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[9]\n",
      "256327\n",
      "443\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199013, 1: 351})\n",
      "Resampled training dataset shape Counter({0: 255884, 1: 255884})\n",
      "Fitting the model... CV[10]\n",
      "('Mean scores: ', ['LogisticRegression', 0.11956608464831955, 0.064831910865825529, 0.88028571428571423, datetime.timedelta(0, 6, 157322)])\n"
     ]
    }
   ],
   "source": [
    "scores = custom_cross_val_3(X, y,lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "data = data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_data(data):\n",
    "\n",
    "    fraud_indices = np.array(data[data.Class == 1].index)\n",
    "    print 'Number of frauds', len(fraud_indices)\n",
    "\n",
    "    non_fraud = data[data.Class==0]\n",
    "    fraud = data[data.Class==1]\n",
    "\n",
    "    print 'number of non fraud: ', len(non_fraud)\n",
    "    non_fraud = non_fraud.loc[np.random.choice(non_fraud.index, len(fraud_indices), replace=False)]\n",
    "\n",
    "    undersampled_data = pd.concat([non_fraud, fraud])\n",
    "    print 'non_fraud after: ', len(non_fraud)\n",
    "\n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X = undersampled_data.ix[:, data.columns != 'Class']\n",
    "    y = undersampled_data.ix[:, data.columns == 'Class']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_under(data, clf, n):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X,y = undersample_data(data)\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        print 'training length: ', len(train_index)\n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        print 'fraud training length', len(y_train_folds[y_train_folds['Class']==1])\n",
    "        print 'test length', len(y_test_fold)\n",
    "        X_res, y_res = X_train_folds, y_train_folds\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_original(data, clf, n):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X = data.ix[:, data.columns != 'Class']\n",
    "    y = data.ix[:, data.columns == 'Class']\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        print len(train_index)\n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        print len(y_train_folds[y_train_folds['Class']==1])\n",
    "        X_res, y_res = X_train_folds, y_train_folds\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  884\n",
      "fraud training length 442\n",
      "test length 100\n",
      "Fitting the model... CV[1]\n",
      "training length:  884\n",
      "fraud training length 442\n",
      "test length 100\n",
      "Fitting the model... CV[2]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[3]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[4]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[5]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[6]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[7]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[8]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[9]\n",
      "training length:  886\n",
      "fraud training length 443\n",
      "test length 98\n",
      "Fitting the model... CV[10]\n",
      "('Mean scores: ', ['LogisticRegression', 0.90722726545375854, 0.96619649967276688, 0.85987755102040819, datetime.timedelta(0, 0, 7256)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LogisticRegression',\n",
       " 0.90722726545375854,\n",
       " 0.96619649967276688,\n",
       " 0.85987755102040819,\n",
       " datetime.timedelta(0, 0, 7256)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cross_val_under(data, lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "256325\n",
      "442\n",
      "Fitting the model... CV[1]\n",
      "256325\n",
      "442\n",
      "Fitting the model... CV[2]\n",
      "256326\n",
      "443\n",
      "Fitting the model... CV[3]\n",
      "256326\n",
      "443\n",
      "Fitting the model... CV[4]\n",
      "256326\n",
      "443\n",
      "Fitting the model... CV[5]\n",
      "256327\n",
      "443\n",
      "Fitting the model... CV[6]\n",
      "256327\n",
      "443\n",
      "Fitting the model... CV[7]\n",
      "256327\n",
      "443\n",
      "Fitting the model... CV[8]\n",
      "256327\n",
      "443\n",
      "Fitting the model... CV[9]\n",
      "256327\n",
      "443\n",
      "Fitting the model... CV[10]\n",
      "('Mean scores: ', ['LogisticRegression', 0.61905577414463908, 0.83352994441218109, 0.60857142857142854, datetime.timedelta(0, 3, 3573)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LogisticRegression',\n",
       " 0.61905577414463908,\n",
       " 0.83352994441218109,\n",
       " 0.60857142857142854,\n",
       " datetime.timedelta(0, 3, 3573)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cross_val_original(data, lr, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCUSTOM CROSS-VAL / n = 10 / RESULTS\\nUNDER\\n('Mean scores: ', ['LogisticRegression', 0.91648916128927205, 0.96546179887028438, 0.87763265306122451, datetime.timedelta(0, 0, 6074)])\\nOVER\\n('Mean scores: ', ['LogisticRegression', 0.11956608464831955, 0.064831910865825529, 0.88028571428571423, datetime.timedelta(0, 6, 157322)])\\nSMOTE\\n('Mean scores: ', ['LogisticRegression', 0.11092022946688154, 0.059684765875965239, 0.87628571428571433, datetime.timedelta(0, 6, 112225)])\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CUSTOM CROSS-VAL / n = 10 / RESULTS\n",
    "====================================\n",
    "ORIGINAL\n",
    "('Mean scores: ', ['LogisticRegression', 0.61991018289378452, 0.83683682271905935, 0.60857142857142854, datetime.timedelta(0, 2, 933120)])\n",
    "UNDER\n",
    "('Mean scores: ', ['LogisticRegression', 0.91648916128927205, 0.96546179887028438, 0.87763265306122451, datetime.timedelta(0, 0, 6074)])\n",
    "OVER\n",
    "('Mean scores: ', ['LogisticRegression', 0.11956608464831955, 0.064831910865825529, 0.88028571428571423, datetime.timedelta(0, 6, 157322)])\n",
    "SMOTE\n",
    "('Mean scores: ', ['LogisticRegression', 0.11092022946688154, 0.059684765875965239, 0.87628571428571433, datetime.timedelta(0, 6, 112225)])\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean scores: ', ['KNeighborsClassifier', 0.0019990661410766563, 0.0010019010295317624, 0.46341463414634143, datetime.timedelta(0, 60, 503710)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['LinearSVC', 0.0046783625730994153, 0.0055096418732782371, 0.0040650406504065045, datetime.timedelta(0, 32, 412505)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.33274691656775085, 0.33060711371947465, 0.68089430894308933, datetime.timedelta(0, 11, 695929)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.52954487358442437, 0.62603126289627709, 0.77642276422764223, datetime.timedelta(0, 11, 912450)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['MLPClassifier', 0.32119199745099025, 0.34342250115575607, 0.52642276422764223, datetime.timedelta(0, 5, 211895)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['GaussianNB', 0.22371270582049371, 0.13795859023131751, 0.70121951219512191, datetime.timedelta(0, 0, 108357)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "                        F1 Score  Precision    Recall   Training Time\n",
      "Classifier                                                           \n",
      "KNeighborsClassifier    0.001999   0.001002  0.463415 00:01:00.503710\n",
      "LinearSVC               0.004678   0.005510  0.004065 00:00:32.412505\n",
      "DecisionTreeClassifier  0.332747   0.330607  0.680894 00:00:11.695929\n",
      "RandomForestClassifier  0.529545   0.626031  0.776423 00:00:11.912450\n",
      "MLPClassifier           0.321192   0.343423  0.526423 00:00:05.211895\n",
      "GaussianNB              0.223713   0.137959  0.701220 00:00:00.108357\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_original(data, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print log \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.06404657933042214, 0.11282051282051282, 0.044715447154471545, datetime.timedelta(0, 0, 1634)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n",
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['LinearSVC', 0.11070707070707071, 0.62962962962962965, 0.067073170731707321, datetime.timedelta(0, 0, 52998)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.89058444824773586, 0.89692417860785845, 0.88617886178861793, datetime.timedelta(0, 0, 9283)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.92404887263215318, 0.97301416895181658, 0.88008130081300806, datetime.timedelta(0, 0, 34621)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['MLPClassifier', 0.26311249137336096, 0.54999999999999993, 0.35569105691056913, datetime.timedelta(0, 0, 24867)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[1]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[2]\n",
      "training length:  656\n",
      "fraud training length 328\n",
      "test length 328\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['GaussianNB', 0.8172287315042176, 0.98041476955028362, 0.70731707317073178, datetime.timedelta(0, 0, 1000)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "                        F1 Score  Precision    Recall   Training Time\n",
      "Classifier                                                           \n",
      "KNeighborsClassifier    0.064047   0.112821  0.044715 00:00:00.001634\n",
      "LinearSVC               0.110707   0.629630  0.067073 00:00:00.052998\n",
      "DecisionTreeClassifier  0.890584   0.896924  0.886179 00:00:00.009283\n",
      "RandomForestClassifier  0.924049   0.973014  0.880081 00:00:00.034621\n",
      "MLPClassifier           0.263112   0.550000  0.355691 00:00:00.024867\n",
      "GaussianNB              0.817229   0.980415  0.707317 00:00:00.001000\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_under(data, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print log \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "KNeighborsClassifier\n",
      "[ 0.          0.          0.01904762]\n",
      "==============================\n",
      "LinearSVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54205607  0.67489712  0.22564103]\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "[ 0.92215569  0.89296636  0.25961538]\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "[ 0.95031056  0.93159609  0.89180328]\n",
      "==============================\n",
      "MLPClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66122449  0.          0.        ]\n",
      "==============================\n",
      "GaussianNB\n",
      "[ 0.92810458  0.7732342   0.77419355]\n",
      "==============================\n",
      "Cross validation training results: \n",
      "[{'KNeighborsClassifier': 0.0063492063492063501}, {'LinearSVC': 0.48086473991631484}, {'DecisionTreeClassifier': 0.69157914469813608}, {'RandomForestClassifier': 0.9245699762999825}, {'MLPClassifier': 0.22040816326530613}, {'GaussianNB': 0.82517744143133009}]\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "X, y = undersample_data(data)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1score = []\n",
    "elapsed_times = []\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    \n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    scores = cross_val_score(clf,X,y, cv=3, scoring='f1')\n",
    "    print scores\n",
    "    mean = np.mean(scores)\n",
    "    f1score.append({name : mean})\n",
    "    print(\"=\"*30)\n",
    "\n",
    "#     log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "#     log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "# log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print f1score \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Other classifiers\n",
    "---\n",
    "Let's now experiment with other classifiers, moving forward with SMOTE oversampled data (performed on training data only).\n",
    "\n",
    "* K NEAREST NEIGHBORS\n",
    "* NEURAL NET\n",
    "* LINEAR SVM \n",
    "* DECISION TREE\n",
    "* NAIVE BAYES\n",
    "* RANDOM FORREST\n",
    "* GAUSSIAN PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K NEAREST NEIGHBORS: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140e6490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.50      0.86      0.63       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "RECALL :  0.863945578231\n"
     ]
    }
   ],
   "source": [
    "################## K NEAREST NEIGHBORS ###################\n",
    "print 'K NEAREST NEIGHBORS: '\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "neigh.fit(X_res, y_res)\n",
    "y_pred = neigh.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print 'RECALL : ', recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NET: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.70      0.82      0.76       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "RECALL :  0.823129251701\n"
     ]
    }
   ],
   "source": [
    "################### NEURAL NET ###################\n",
    "print 'NEURAL NET: '\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp.fit(X_res, y_res)\n",
    "y_pred = mlp.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print 'RECALL : ', recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.40      0.76      0.52       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "RECALL :  0.755102040816\n"
     ]
    }
   ],
   "source": [
    "################### DECISION TREE ###################\n",
    "print 'DECISION TREE: '\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(X_res, y_res)\n",
    "y_pred = dt.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print 'RECALL : ', recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR SVM: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.38      0.69      0.49       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "RECALL:  0.69387755102\n"
     ]
    }
   ],
   "source": [
    "################### LINEAR SVM ###################\n",
    "print 'LINEAR SVM: '\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "lin_svm = SVC()\n",
    "\n",
    "lin_svm.fit(X_res, y_res)\n",
    "y_pred = lin_svm.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print 'RECALL: ', recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.91      0.80      0.85       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n",
      "0.795918367347\n"
     ]
    }
   ],
   "source": [
    "################### RANDOM FOREST ###################\n",
    "print 'RANDOM FOREST: '\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_res, y_res)\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     85296\n",
      "          1       0.06      0.86      0.11       147\n",
      "\n",
      "avg / total       1.00      0.98      0.99     85443\n",
      "\n",
      "0.863945578231\n"
     ]
    }
   ],
   "source": [
    "################### NAIVE BAYES ###################\n",
    "print 'Gaussian Naive Bayes: '\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_res, y_res)\n",
    "y_pred = gnb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_names = [0,1]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pred)\n",
    "print recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarising classifiers and averaging runs\n",
    "\n",
    "#### Here, instead of just training a classifier once and predicting, I create a function that averages results over 3 runs. These 3 runs incoperate a new, fresh random test-train split of the data. In addition, SMOTE is used for every train data, with each iteration. So all three runs are new random tests in the sense that the split of data and resampling is different. We then average the important metrics, to be confident in the results.\n",
    "\n",
    "#### In a lot of machine learning applications, one may use a similar technique of cross-validation. This is normally preferable on a small subsample of the data to see what classifiers perform best. Seeing as we want to ultimate set baselines for these models, I just run them on the full dataset to get full results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_sample(x_data, y_data): \n",
    "    ''' 1) Generate new, random train-test split\n",
    "        2) Random smote oversample the train data, keeping test data unseen\n",
    "        3) Use this new train-test split to fit and test model\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data,y_data,test_size = 0.3)\n",
    "\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(X_train, y_train)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(x_data, y_data):\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(x_data, y_data)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val(X_train, y_train, clf):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "        cv=cv+1\n",
    "        \n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X_train[train_index]\n",
    "        y_train_folds = y_train[train_index]\n",
    "        X_test_fold = X_train[test_index]\n",
    "        y_test_fold = y_train[test_index]\n",
    "        \n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_train_folds, y_train_folds)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_2(X, y, clf, n):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=42)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        print len(train_index)\n",
    "        clone_clf = clone(clf)\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        print len(y_train_folds[y_train_folds['Class']==1])\n",
    "        X_res, y_res = smote_data(X_train_folds, y_train_folds )\n",
    "        \n",
    "        \n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print('Fitting the model... CV[{}]'.format(cv))\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Cross validating... \n",
      "\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[1]\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[2]\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.73244077978869715, 0.59251167150271034, 0.95934959349593496, datetime.timedelta(0, 2, 743151)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['KNeighborsClassifier',\n",
       " 0.73244077978869715,\n",
       " 0.59251167150271034,\n",
       " 0.95934959349593496,\n",
       " datetime.timedelta(0, 2, 743151)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print neigh\n",
    "custom_cross_val_2(X, y, neigh, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[1]\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[2]\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['MLPClassifier', 0.86843903354167284, 0.80873341301997892, 0.93902439024390238, datetime.timedelta(0, 47, 162002)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MLPClassifier',\n",
       " 0.86843903354167284,\n",
       " 0.80873341301997892,\n",
       " 0.93902439024390238,\n",
       " datetime.timedelta(0, 47, 162002)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cross_val_2(X, y, mlp, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['GaussianNB', 0.10717066723583384, 0.057195877947314087, 0.85569105691056901, datetime.timedelta(0, 0, 313755)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GaussianNB',\n",
       " 0.10717066723583384,\n",
       " 0.057195877947314087,\n",
       " 0.85569105691056901,\n",
       " datetime.timedelta(0, 0, 313755)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cross_val_2(X, y, gnb, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['MLPClassifier', 0.68900042936554096, 0.67340796918261703, 0.72560975609756095, datetime.timedelta(0, 37, 494422)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MLPClassifier',\n",
       " 0.68900042936554096,\n",
       " 0.67340796918261703,\n",
       " 0.72560975609756095,\n",
       " datetime.timedelta(0, 37, 494422)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_cross_val_2(X, y, mlp, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.50021784664418822, 0.37562230441049321, 0.83130081300812997, datetime.timedelta(0, 3, 104011)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['LinearSVC', 0.11634819819482807, 0.062385966273416193, 0.86991869918699194, datetime.timedelta(0, 98, 645728)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.42103247711214165, 0.30221442709666074, 0.71544715447154472, datetime.timedelta(0, 34, 938850)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.80383877343293453, 0.84003064309081121, 0.7825203252032521, datetime.timedelta(0, 34, 851308)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['MLPClassifier', 0.68711079960574217, 0.67149210052177166, 0.72764227642276413, datetime.timedelta(0, 40, 762667)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[1]\n",
      "189871\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "Fitting the model... CV[2]\n",
      "189872\n",
      "328\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "Fitting the model... CV[3]\n",
      "('Mean scores: ', ['GaussianNB', 0.1070355192095666, 0.057118318033931526, 0.85569105691056901, datetime.timedelta(0, 0, 283884)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "                        F1 Score  Precision    Recall   Training Time\n",
      "Classifier                                                           \n",
      "KNeighborsClassifier    0.500218   0.375622  0.831301 00:00:03.104011\n",
      "LinearSVC               0.116348   0.062386  0.869919 00:01:38.645728\n",
      "DecisionTreeClassifier  0.421032   0.302214  0.715447 00:00:34.938850\n",
      "RandomForestClassifier  0.803839   0.840031  0.782520 00:00:34.851308\n",
      "MLPClassifier           0.687111   0.671492  0.727642 00:00:40.762667\n",
      "GaussianNB              0.107036   0.057118  0.855691 00:00:00.283884\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Setting up dataframe table properties for generalised test data\n",
    "log_general = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "test_general_graph_data = {}\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_2(X, y, clf, 3)\n",
    "    \n",
    "    # generalised test\n",
    "    start = datetime.datetime.now()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "        \n",
    "    y_pred = clf.predict(X_test)\n",
    "    prfs = precision_recall_fscore_support(y_test, y_pred, pos_label=1, average='binary')    \n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print log \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        F1 Score  Precision    Recall   Training Time\n",
      "Classifier                                                           \n",
      "KNeighborsClassifier    0.500218   0.375622  0.831301 00:00:03.104011\n",
      "LinearSVC               0.116348   0.062386  0.869919 00:01:38.645728\n",
      "DecisionTreeClassifier  0.421032   0.302214  0.715447 00:00:34.938850\n",
      "RandomForestClassifier  0.803839   0.840031  0.782520 00:00:34.851308\n",
      "MLPClassifier           0.687111   0.671492  0.727642 00:00:40.762667\n",
      "GaussianNB              0.107036   0.057118  0.855691 00:00:00.283884\n"
     ]
    }
   ],
   "source": [
    "print log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_2(X, y, clf, 4)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print log \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 198987, 1: 198987})\n",
      "Cross validating... \n",
      "\n",
      "Fitting the model... CV[2]\n",
      "Fitting the model... CV[3]\n",
      "Fitting the model... CV[4]\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.99861740620854922, 0.99723863930033596, 1.0, datetime.timedelta(0, 1, 402998)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:32: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "5 columns passed, passed data had 4 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-245b458baaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mgeneral_test_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgeneral_log_entry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneral_test_entry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mlog_general\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_general\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneral_log_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6250\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m-> 6251\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m   6252\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6253\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[0;32m/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6328\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6329\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[0;32m-> 6330\u001b[0;31m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m   6331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6385\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6386\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[0;32m-> 6387\u001b[0;31m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[1;32m   6388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6389\u001b[0m     \u001b[0;31m# provide soft conversion of object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 5 columns passed, passed data had 4 columns"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Setting up dataframe table properties for generalised test data\n",
    "log_general = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "test_general_graph_data = {}\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "    entry = custom_cross_val(X_res, y_res, clf)\n",
    "    \n",
    "    # generalised test\n",
    "    start = datetime.datetime.now()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "        \n",
    "    y_pred = clf.predict(X_test)\n",
    "    prfs = precision_recall_fscore_support(y_test, y_pred, pos_label=1, average='binary')\n",
    "    \n",
    "    general_test_entry = [name, prfs[0], prfs[1], prfs[2], elapsed]\n",
    "    general_log_entry = pd.DataFrame([general_test_entry], columns=log_cols)\n",
    "    log_general = log_general.append(general_log_entry)\n",
    "    \n",
    "    # data for precision recall graphs\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "    \n",
    "    test_general_graph_data.update(name, (precision, recall, thresholds))\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log.set_index('Classifier', inplace=True)\n",
    "print 'Cross validation training results: '\n",
    "print log \n",
    "print 'Generalised results on new test data: '\n",
    "print log_general\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to visualise results\n",
    "ax = log[['F1 Score']].plot(kind='bar', title =\"F1 Score\", figsize=(15, 10),legend=True, fontsize=12)\n",
    "ax.set_xlabel(\"Classifier\", fontsize=12)\n",
    "ax.set_ylabel(\"Score\", fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = log[['Recall']].plot(kind='bar', title =\"Recall\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax.set_xlabel(\"Classifier\", fontsize=12)\n",
    "ax.set_ylabel(\"Score\", fontsize=12)\n",
    "plt.subplot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = log[['Precision']].plot(kind='bar', title =\"Precision\", figsize=(15, 10), legend=True, fontsize=12)\n",
    "ax.set_xlabel(\"Classifier\", fontsize=12)\n",
    "ax.set_ylabel(\"Score\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(precision_recall_dict):\n",
    "    plt.figure()\n",
    "    i = 221\n",
    "    for name, values in precision_recall_dict:\n",
    "        \n",
    "        plt.subplot(i)\n",
    "        plt.plot(values[0], values[1])\n",
    "        plt.xlabel(\"recall\")\n",
    "        plt.ylabel(\"precision\")\n",
    "        plt.title(name)\n",
    "        plt.grid(True)\n",
    "        i = i + 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cross-val on original (unbalanced) data\n",
    "==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier                                                           \n",
    "KNeighborsClassifier    0.001999   0.001002  0.463415 00:01:00.503710\n",
    "LinearSVC               0.004678   0.005510  0.004065 00:00:32.412505\n",
    "DecisionTreeClassifier  0.332747   0.330607  0.680894 00:00:11.695929\n",
    "RandomForestClassifier  0.529545   0.626031  0.776423 00:00:11.912450\n",
    "MLPClassifier           0.321192   0.343423  0.526423 00:00:05.211895\n",
    "GaussianNB              0.223713   0.137959  0.701220 00:00:00.108357\n",
    "==============================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cross-val on UnderSampled data\n",
    "==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier                                                           \n",
    "KNeighborsClassifier    0.006202   0.013072  0.004065 00:00:00.001172\n",
    "LinearSVC               0.321363   0.498962  0.329268 00:00:00.048264\n",
    "DecisionTreeClassifier  0.682836   0.825479  0.611789 00:00:00.008920\n",
    "RandomForestClassifier  0.924536   0.979922  0.876016 00:00:00.033931\n",
    "MLPClassifier           0.219945   0.165638  0.327236 00:00:00.012885\n",
    "GaussianNB              0.829327   0.985367  0.721545 00:00:00.001068\n",
    "==============================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cross-val accounting properly for oversampling with smote\n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier                                                           \n",
    "KNeighborsClassifier    0.500218   0.375622  0.831301 00:00:03.104011\n",
    "LinearSVC               0.116348   0.062386  0.869919 00:01:38.645728\n",
    "DecisionTreeClassifier  0.421032   0.302214  0.715447 00:00:34.938850\n",
    "RandomForestClassifier  0.803839   0.840031  0.782520 00:00:34.851308\n",
    "MLPClassifier           0.687111   0.671492  0.727642 00:00:40.762667\n",
    "GaussianNB              0.107036   0.057118  0.855691 00:00:00.283884\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SUMMARY OF RESULTS (AVG over three random iterations)\n",
    "=====================================================================\n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier                                                           \n",
    "KNeighborsClassifier    0.611444   0.476876  0.853809 00:00:01.758558\n",
    "LinearSVC               0.119385   0.063951  0.896587 00:01:24.125692\n",
    "DecisionTreeClassifier  0.536858   0.411079  0.774736 00:00:23.579666\n",
    "RandomForestClassifier  0.846437   0.879453  0.816384 00:00:23.179558\n",
    "MLPClassifier           0.750672   0.704481  0.807383 00:00:27.263501\n",
    "GaussianNB              0.109543   0.058463  0.870450 00:00:00.213850\n",
    "=====================================================================\n",
    "'''\n",
    "\n",
    "print log\n",
    "print log_general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Summary\n",
    "\n",
    "#### F1-score:\n",
    "F1-score is the harmonic average of precision and recall. We can define precision as intuitively the ability of the classifier not to label as positive, a sample that is negative. Similarly we define recall as intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "So why do we care about F1 score? \n",
    "\n",
    "#### Context of the bank\n",
    "In the context of banks and how these metrics add or lose value to them, we indeed care about F1 score. As you can see from the results table, LinearSVC has the highest Recall score, which means it is great at finding true fraudulent cases. However, it's precision is very low at 0.11. This essentially means that the classifier performs badly when it comes to predicting some non-fraudulent data and falsly labelling them as fraud. Why is this bad? This is bad because the loses the bank money and gives customers a bad experience. If we have bad precision then we falsly classify as fraud a lot and we freeze customer cards and accounts and send them a text to say we believe there is fraud etc. Only to ultimately verify that everything is benign and reverse the situation. This is very bad and gives a bad impression for the customer, who may indeed change bank or lose faith in the bank's intelligence systems.\n",
    "\n",
    "#### Hence, we care about F1 score, which is the balance between these two metrics. Recall: being able to catch true frauds and Precision: being able to correctly classify and reduce the number of false positives.\n",
    "In this light, we see that\n",
    "\n",
    "#### RandomForestClassifier  0.846437\n",
    "\n",
    "is very favourable and performs rather well in comparison to the other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
