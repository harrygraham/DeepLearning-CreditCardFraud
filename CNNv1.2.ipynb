{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model 1\n",
    "\n",
    "## The approach:\n",
    "\n",
    "### Without time feature\n",
    "### Pass 1x29 vectors into a convolutional layer, with kernel size 29, with some D number of filters\n",
    "### Add extra conv and dense layer to the model to see the effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First run: single conv layer single dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:18: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199012, 1: 199012})\n",
      "(398024, 29) <type 'numpy.ndarray'>\n",
      "(398024,)\n",
      "(85443, 2)\n",
      "(398024, 2)\n",
      "Epoch 1/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0307 - acc: 0.9898\n",
      "Epoch 2/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9991\n",
      "Epoch 3/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0046 - acc: 0.9993\n",
      "Epoch 4/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 5/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 6/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 7/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 8/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0029 - acc: 0.9998\n",
      "Epoch 9/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 10/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 11/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 12/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0031 - acc: 0.9997\n",
      "Epoch 13/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 16/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 17/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 18/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 19/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 20/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 21/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 22/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 23/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 24/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 25/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 26/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 27/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 28/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 29/50\n",
      "398024/398024 [==============================] - 5s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 30/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 31/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 33/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "398024/398024 [==============================] - 5s 12us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 49/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 50/50\n",
      "398024/398024 [==============================] - 4s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "85443/85443 [==============================] - 0s 5us/step\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "# from keras_diagram import ascii\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import keras\n",
    "\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# Normalise and reshape the Amount column, so it's values lie between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data['norm_Amount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1,1))\n",
    "\n",
    "# Drop the old Amount column and also the Time column as we don't want to include this at this stage\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.ix[:, data.columns != 'Class']\n",
    "y = data.ix[:, data.columns == 'Class']\n",
    "\n",
    "def generate_train_test_sample(x_data, y_data): \n",
    "    ''' 1) Generate new, random train-test split\n",
    "        2) Random smote oversample the train data, keeping test data unseen\n",
    "        3) Use this new train-test split to fit and test model\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data,y_data,test_size = 0.3)\n",
    "\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(X_train, y_train)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res, X_test, y_test\n",
    "\n",
    "########################################################################\n",
    "\n",
    "X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "print X_res.shape, type(X_res)\n",
    "print y_res.shape\n",
    "\n",
    "X_train = X_res.reshape(X_res.shape[0], 29, 1)\n",
    "Y_train = y_res.reshape(y_res.shape[0], 1)\n",
    "X_test = X_test.values.reshape(X_test.values.shape[0], 29, 1)\n",
    "Y_test = y_test.values.reshape(y_test.values.shape[0], 1)\n",
    "\n",
    "Y_test = keras.utils.to_categorical(Y_test)\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "print Y_test.shape\n",
    "print Y_train.shape\n",
    "\n",
    "\n",
    "seed(2017)\n",
    "conv = Sequential()\n",
    "conv.add(Conv1D(256, 29, input_shape=(29, 1), activation='relu'))\n",
    "\n",
    "conv.add(Flatten())\n",
    "\n",
    "conv.add(Dense(300, activation = 'relu'))\n",
    "conv.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv.fit(X_train, Y_train, batch_size = 500, epochs = 50, verbose = 1)\n",
    "score = conv.evaluate(X_test, Y_test, batch_size=500)\n",
    "\n",
    "y_pred = conv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "[Precision, Recall, F1, Support]\n",
      "====================================================================================================\n",
      "0:      0.999742023241         0.999460745812      0.99960136474      85303   \n",
      "1:      0.719512195122         0.842857142857      0.776315789474      140   \n",
      "====================================================================================================\n",
      "F1 Score, Fraud Class = 0.776315789474\n"
     ]
    }
   ],
   "source": [
    "cutt_off_tr = 0.5\n",
    "y_pred[np.where(y_pred>=cutt_off_tr)] = 1\n",
    "y_pred[np.where(y_pred<cutt_off_tr)]  = 0\n",
    "\n",
    "prfs0 = precision_recall_fscore_support(Y_test, y_pred, labels=[0])\n",
    "\n",
    "print 'Classification Report: \\n'\n",
    "print '[Precision, Recall, F1, Support]'\n",
    "print '='*100\n",
    "print '0:      {}         {}      {}      {}   '.format(prfs0[0][0], prfs0[1][0], prfs0[2][0], prfs0[3][0])\n",
    "print '1:      {}         {}      {}      {}   '.format(prfs0[0][1], prfs0[1][1], prfs0[2][1], prfs0[3][1])\n",
    "print '='*100\n",
    "\n",
    "print 'F1 Score, Fraud Class = {}'.format(prfs0[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 1, 256)            7680      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1, 256)            65792     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               77100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 180,874\n",
      "Trainable params: 180,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print conv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of first run\n",
    "\n",
    "We can see that this very simple model, with just a single convolution layer piped into a simple dense network, already gives comparable F1 to our top two baseline classifiers:\n",
    "\n",
    "CNNv1.1:                 0.776316\n",
    "\n",
    "RandomForestClassifier:  0.846437   \n",
    "MLPClassifier:           0.750672 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second run, with added conv and dense layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199022, 1: 199022})\n",
      "(398044, 29) <type 'numpy.ndarray'>\n",
      "(398044,)\n",
      "(85443, 2)\n",
      "(398044, 2)\n",
      "Epoch 1/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0283 - acc: 0.9903\n",
      "Epoch 2/50\n",
      "398044/398044 [==============================] - 11s 27us/step - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 3/50\n",
      "398044/398044 [==============================] - 11s 26us/step - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 4/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 5/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 6/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 7/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 9/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0031 - acc: 0.9997\n",
      "Epoch 11/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 12/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 13/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "398044/398044 [==============================] - 11s 27us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 17/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 18/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 19/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 20/50\n",
      "398044/398044 [==============================] - 9s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 21/50\n",
      "398044/398044 [==============================] - 9s 24us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 22/50\n",
      "398044/398044 [==============================] - 9s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 23/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 24/50\n",
      "398044/398044 [==============================] - 11s 27us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 25/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 26/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 27/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 28/50\n",
      "398044/398044 [==============================] - 11s 27us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 29/50\n",
      "398044/398044 [==============================] - 11s 27us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 30/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 31/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 33/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "398044/398044 [==============================] - 10s 24us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "398044/398044 [==============================] - 11s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "398044/398044 [==============================] - 10s 26us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "398044/398044 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "85443/85443 [==============================] - 1s 8us/step\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# CNNv1.2\n",
    "\n",
    "X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "print X_res.shape, type(X_res)\n",
    "print y_res.shape\n",
    "\n",
    "X_train = X_res.reshape(X_res.shape[0], 29, 1)\n",
    "Y_train = y_res.reshape(y_res.shape[0], 1)\n",
    "X_test = X_test.values.reshape(X_test.values.shape[0], 29, 1)\n",
    "Y_test = y_test.values.reshape(y_test.values.shape[0], 1)\n",
    "\n",
    "Y_test = keras.utils.to_categorical(Y_test)\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "print Y_test.shape\n",
    "print Y_train.shape\n",
    "\n",
    "\n",
    "seed(2017)\n",
    "conv = Sequential()\n",
    "conv.add(Conv1D(256, 29, input_shape=(29, 1), activation='relu'))\n",
    "conv.add(Conv1D(256, 1, activation='relu'))\n",
    "conv.add(Flatten())\n",
    "\n",
    "conv.add(Dense(300, activation = 'relu'))\n",
    "conv.add(Dense(100, activation = 'relu'))\n",
    "conv.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "conv.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "conv.fit(X_train, Y_train, batch_size = 500, epochs = 50, verbose = 1)\n",
    "score = conv.evaluate(X_test, Y_test, batch_size=500)\n",
    "\n",
    "y_pred = conv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "[Precision, Recall, F1, Support]\n",
      "====================================================================================================\n",
      "0:      0.999718584009         0.999601374087      0.999659975612      85293   \n",
      "1:      0.7875         0.84      0.812903225806      150   \n",
      "====================================================================================================\n",
      "F1 Score, Fraud Class = 0.812903225806\n"
     ]
    }
   ],
   "source": [
    "y_pred[np.where(y_pred>=cutt_off_tr)] = 1\n",
    "y_pred[np.where(y_pred<cutt_off_tr)]  = 0\n",
    "\n",
    "prfs0 = precision_recall_fscore_support(Y_test, y_pred, labels=[0])\n",
    "\n",
    "print 'Classification Report: \\n'\n",
    "print '[Precision, Recall, F1, Support]'\n",
    "print '='*100\n",
    "print '0:      {}         {}      {}      {}   '.format(prfs0[0][0], prfs0[1][0], prfs0[2][0], prfs0[3][0])\n",
    "print '1:      {}         {}      {}      {}   '.format(prfs0[0][1], prfs0[1][1], prfs0[2][1], prfs0[3][1])\n",
    "print '='*100\n",
    "\n",
    "print 'F1 Score, Fraud Class = {}'.format(prfs0[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of second run\n",
    "\n",
    "This seems very promising, already matching our best baseline classifier, with our first CNN approach.\n",
    "\n",
    "#### However, we should at least average runs to get confidence in results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNv1 averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_run():\n",
    "    reports = []\n",
    "    for i in range(3):\n",
    "        X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "        print X_res.shape, type(X_res)\n",
    "        print y_res.shape\n",
    "\n",
    "        X_train = X_res.reshape(X_res.shape[0], 29, 1)\n",
    "        Y_train = y_res.reshape(y_res.shape[0], 1)\n",
    "        X_test = X_test.values.reshape(X_test.values.shape[0], 29, 1)\n",
    "        Y_test = y_test.values.reshape(y_test.values.shape[0], 1)\n",
    "\n",
    "        Y_test = keras.utils.to_categorical(Y_test)\n",
    "        Y_train = keras.utils.to_categorical(Y_train)\n",
    "        print Y_test.shape\n",
    "        print Y_train.shape\n",
    "\n",
    "\n",
    "        seed(2017)\n",
    "        conv = Sequential()\n",
    "        conv.add(Conv1D(256, 29, input_shape=(29, 1), activation='relu'))\n",
    "        conv.add(Flatten())\n",
    "        conv.add(Dense(300, activation = 'relu'))\n",
    "        conv.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "        sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "        conv.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "        conv.fit(X_train, Y_train, batch_size = 500, epochs = 50, verbose = 1, callbacks=[keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=1, mode='auto')])\n",
    "        score = conv.evaluate(X_test, Y_test, batch_size=500)\n",
    "\n",
    "        y_pred = conv.predict(X_test)\n",
    "\n",
    "        cutt_off_tr = 0.5\n",
    "        y_pred[np.where(y_pred>=cutt_off_tr)] = 1\n",
    "        y_pred[np.where(y_pred<cutt_off_tr)]  = 0\n",
    "\n",
    "        prfs0 = precision_recall_fscore_support(Y_test, y_pred, labels=[0])\n",
    "        reports.append(prfs0)\n",
    "    \n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199015, 1: 199015})\n",
      "(398030, 29) <type 'numpy.ndarray'>\n",
      "(398030,)\n",
      "(85443, 2)\n",
      "(398030, 2)\n",
      "Epoch 1/50\n",
      "398030/398030 [==============================] - 6s 14us/step - loss: 0.0313 - acc: 0.9895\n",
      "Epoch 2/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0060 - acc: 0.9989\n",
      "Epoch 3/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 4/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 5/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 6/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 7/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 8/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 9/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 11/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 12/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 13/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398030/398030 [==============================] - 5s 11us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00016: early stopping\n",
      "85443/85443 [==============================] - 1s 7us/step\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199032, 1: 199032})\n",
      "(398064, 29) <type 'numpy.ndarray'>\n",
      "(398064,)\n",
      "(85443, 2)\n",
      "(398064, 2)\n",
      "Epoch 1/50\n",
      "398064/398064 [==============================] - 5s 13us/step - loss: 0.0311 - acc: 0.9899\n",
      "Epoch 2/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 3/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0047 - acc: 0.9993\n",
      "Epoch 4/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0043 - acc: 0.9993\n",
      "Epoch 5/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0078 - acc: 0.9989\n",
      "Epoch 6/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 7/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 9/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 10/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 11/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 12/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 13/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398064/398064 [==============================] - 5s 12us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 00016: early stopping\n",
      "85443/85443 [==============================] - 1s 8us/step\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199021, 1: 199021})\n",
      "(398042, 29) <type 'numpy.ndarray'>\n",
      "(398042,)\n",
      "(85443, 2)\n",
      "(398042, 2)\n",
      "Epoch 1/50\n",
      "398042/398042 [==============================] - 5s 13us/step - loss: 0.0328 - acc: 0.9886\n",
      "Epoch 2/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0061 - acc: 0.9989\n",
      "Epoch 3/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0049 - acc: 0.9992\n",
      "Epoch 4/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0040 - acc: 0.9995\n",
      "Epoch 5/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 6/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 7/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 9/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 11/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 12/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0059 - acc: 0.9992\n",
      "Epoch 13/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 14/50\n",
      "398042/398042 [==============================] - 5s 11us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 00014: early stopping\n",
      "85443/85443 [==============================] - 1s 8us/step\n"
     ]
    }
   ],
   "source": [
    "reports = average_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 AVG = 0.771745237875\n"
     ]
    }
   ],
   "source": [
    "results = [reports[0][2][1],reports[1][2][1],reports[1][2][1]]\n",
    "avg_f1 = np.mean(results)\n",
    "print 'F1 AVG = {}'.format(avg_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNv1.2 averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_run():\n",
    "    reports = []\n",
    "    for i in range(3):\n",
    "        X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "        print X_res.shape, type(X_res)\n",
    "        print y_res.shape\n",
    "\n",
    "        X_train = X_res.reshape(X_res.shape[0], 29, 1)\n",
    "        Y_train = y_res.reshape(y_res.shape[0], 1)\n",
    "        X_test = X_test.values.reshape(X_test.values.shape[0], 29, 1)\n",
    "        Y_test = y_test.values.reshape(y_test.values.shape[0], 1)\n",
    "\n",
    "        Y_test = keras.utils.to_categorical(Y_test)\n",
    "        Y_train = keras.utils.to_categorical(Y_train)\n",
    "        print Y_test.shape\n",
    "        print Y_train.shape\n",
    "\n",
    "\n",
    "        seed(2017)\n",
    "        conv = Sequential()\n",
    "        conv.add(Conv1D(256, 29, input_shape=(29, 1), activation='relu'))\n",
    "        conv.add(Conv1D(256, 1, activation='relu'))\n",
    "        conv.add(Flatten())\n",
    "\n",
    "        conv.add(Dense(300, activation = 'relu'))\n",
    "        conv.add(Dense(100, activation = 'relu'))\n",
    "        conv.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "        sgd = SGD(lr = 0.1, momentum = 0.9, decay = 0, nesterov = False)\n",
    "        conv.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "        conv.fit(X_train, Y_train, batch_size = 500, epochs = 50, verbose = 1, callbacks=[keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=5, verbose=0, mode='auto')])\n",
    "        score = conv.evaluate(X_test, Y_test, batch_size=500)\n",
    "\n",
    "        y_pred = conv.predict(X_test)\n",
    "\n",
    "        cutt_off_tr = 0.5\n",
    "        y_pred[np.where(y_pred>=cutt_off_tr)] = 1\n",
    "        y_pred[np.where(y_pred<cutt_off_tr)]  = 0\n",
    "\n",
    "        prfs0 = precision_recall_fscore_support(Y_test, y_pred, labels=[0])\n",
    "        reports.append(prfs0)\n",
    "    \n",
    "    return reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199028, 1: 199028})\n",
      "(398056, 29) <type 'numpy.ndarray'>\n",
      "(398056,)\n",
      "(85443, 2)\n",
      "(398056, 2)\n",
      "Epoch 1/50\n",
      "398056/398056 [==============================] - 11s 27us/step - loss: 0.0274 - acc: 0.9904\n",
      "Epoch 2/50\n",
      "398056/398056 [==============================] - 13s 32us/step - loss: 0.0114 - acc: 0.9980\n",
      "Epoch 3/50\n",
      "398056/398056 [==============================] - 12s 31us/step - loss: 0.0048 - acc: 0.9992 0s - loss: 0.0048 - a\n",
      "Epoch 4/50\n",
      "398056/398056 [==============================] - 12s 30us/step - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 5/50\n",
      "398056/398056 [==============================] - 13s 32us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 6/50\n",
      "398056/398056 [==============================] - 12s 31us/step - loss: 0.0036 - acc: 0.9995\n",
      "Epoch 7/50\n",
      "398056/398056 [==============================] - 13s 31us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "398056/398056 [==============================] - 12s 30us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 9/50\n",
      "398056/398056 [==============================] - 11s 27us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398056/398056 [==============================] - 11s 27us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 11/50\n",
      "398056/398056 [==============================] - 10s 26us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 12/50\n",
      "398056/398056 [==============================] - 10s 26us/step - loss: 0.0028 - acc: 0.9998\n",
      "Epoch 13/50\n",
      "398056/398056 [==============================] - 10s 25us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398056/398056 [==============================] - 10s 25us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 15/50\n",
      "398056/398056 [==============================] - 10s 24us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398056/398056 [==============================] - 10s 24us/step - loss: 0.0027 - acc: 0.9998\n",
      "85443/85443 [==============================] - 1s 10us/step\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199033, 1: 199033})\n",
      "(398066, 29) <type 'numpy.ndarray'>\n",
      "(398066,)\n",
      "(85443, 2)\n",
      "(398066, 2)\n",
      "Epoch 1/50\n",
      "398066/398066 [==============================] - 10s 26us/step - loss: 0.0274 - acc: 0.9901\n",
      "Epoch 2/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0091 - acc: 0.9984\n",
      "Epoch 3/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 4/50\n",
      "398066/398066 [==============================] - 10s 25us/step - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 5/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0032 - acc: 0.9997\n",
      "Epoch 6/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 7/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 8/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 9/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0030 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 11/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 12/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 13/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0027 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 15/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398066/398066 [==============================] - 10s 25us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 17/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 18/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 19/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 20/50\n",
      "398066/398066 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "85443/85443 [==============================] - 1s 10us/step\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199026, 1: 199026})\n",
      "(398052, 29) <type 'numpy.ndarray'>\n",
      "(398052,)\n",
      "(85443, 2)\n",
      "(398052, 2)\n",
      "Epoch 1/50\n",
      "398052/398052 [==============================] - 10s 26us/step - loss: 0.0266 - acc: 0.9904\n",
      "Epoch 2/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0125 - acc: 0.9979\n",
      "Epoch 3/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0054 - acc: 0.9990\n",
      "Epoch 4/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 5/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0035 - acc: 0.9995\n",
      "Epoch 6/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 7/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 8/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0029 - acc: 0.9997\n",
      "Epoch 9/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 10/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0028 - acc: 0.9997\n",
      "Epoch 11/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 12/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 13/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0027 - acc: 0.9997\n",
      "Epoch 14/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 17/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 18/50\n",
      "398052/398052 [==============================] - 10s 25us/step - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 19/50\n",
      "398052/398052 [==============================] - 10s 24us/step - loss: 0.0023 - acc: 0.9998\n",
      "85443/85443 [==============================] - 1s 10us/step\n"
     ]
    }
   ],
   "source": [
    "reports = average_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 AVG = 0.810230099502\n"
     ]
    }
   ],
   "source": [
    "results = [reports[0][2][1],reports[1][2][1],reports[1][2][1]]\n",
    "avg_f1 = np.mean(results)\n",
    "print 'F1 AVG = {}'.format(avg_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNv1 : F1 AVG = 0.771745237875\n",
    "# CNNv1.2: F1 AVG = 0.810230099502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
