{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "### Here we walk through some data exploration and do work on our baseline models.\n",
    "\n",
    "### The outline is as follows:\n",
    "\n",
    "1. Explore data and perform any necessary pre-processing\n",
    "2. Run simple logistic regression classifer on dataset\n",
    "3. How cross validation will be done with resampling and metrics\n",
    "4. Try resampling methods using this classifer\n",
    "5. Implement other baseline classifiers using all sampling techniques, for comparison \n",
    "6. See briefly what tuning can be done (Decision boundary thresholds, sampling ratios, best classifier parameters etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. \n",
    "\n",
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "5  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  0.081213  0.464960  ...   -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7 -3.807864  0.615375  ...    1.943465 -1.015455  0.057504 -0.649709   \n",
       "8  0.851084 -0.392048  ...   -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9  0.069539 -0.736727  ...   -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6  0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8  0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9 -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, the features have been normalised, except Time and Amount.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the Amount column and drop the Time column\n",
    "\n",
    " Here we normalise the Amount column to align better with the other features in the data. This is to eliminate the influence of one feature over another and also to aid gradient descent learning. This is done by adding a new column that is the normalised version of the current Amount column and then dropping the old one. \n",
    "\n",
    " We also drop the Time column completely. The reason for this is that the time data is simply a timestamp and for the purposes of obtaining baseline classification results, we can omit this and work solely on classification from the 29 other features, instead of introducing time series, temporal classification. Also, as there will be no feature engineering done here, timestamps over 2 days will not be useful.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Norm_Amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Norm_Amount        V1        V2        V3        V4        V5        V6  \\\n",
       "0     0.244964 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    -0.342475  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2     1.160686 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3     0.140534 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4    -0.073403 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...         V20       V21       V22  \\\n",
       "0  0.239599  0.098698  0.363787  ...    0.251412 -0.018307  0.277838   \n",
       "1 -0.078803  0.085102 -0.255425  ...   -0.069083 -0.225775 -0.638672   \n",
       "2  0.791461  0.247676 -1.514654  ...    0.524980  0.247998  0.771679   \n",
       "3  0.237609  0.377436 -1.387024  ...   -0.208038 -0.108300  0.005274   \n",
       "4  0.592941 -0.270533  0.817739  ...    0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise and reshape the Amount column, so it's values lie between -1 and 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "norm = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data.insert(loc=0, column='Norm_Amount', value=norm)\n",
    "\n",
    "# Drop the old Amount column and also the Time column\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "In a typical data science machine learning workflow, one would usually explore the data and engineer extra features based on domain knowledge of the data and insights into what else might be useful. In this case however as the data is post-PCA and anonymised, it makes no sense to engineer further features. There could be some potential ideas such as engineering features based on transactions in a small space of time or large transaction amounts etc but since this is for baseline work only and that the data is only for a 2 day period, we wont engineer any features  or include the time column in our training.  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1114e8a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print a plot of class balance\n",
    "classes = pd.value_counts(data['Class'], sort=True).sort_index()\n",
    "classes.plot(kind = 'bar')\n",
    "plt.show()\n",
    "print classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.172748563062\n"
     ]
    }
   ],
   "source": [
    "# Print percentage of fraudulent cases\n",
    "print len(data[data['Class']==1]) / float( len(data[data['Class']==0]) + len(data[data['Class']==1]) ) *100\n",
    "# 492 / 284,807 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we see the data is very highy unbalanced, with fraudulent examples only accounting for a mere 0.17% of the total dataset.\n",
    "\n",
    "### Problem with Accuracy as a metric\n",
    "In a lot of machine learning projects, Accuracy is a common metric to use to evaluate the perform of classification problems. However in our case this will not work. \n",
    "\n",
    "#### Even if we completely classified everything we see as non fraudluent, the model would still be deemed to be 99.83% accurate, which is incredibly high. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics we care about\n",
    "\n",
    "#### F1-score:\n",
    "F1-score is the harmonic average of precision and recall. We can define precision as intuitively the ability of the classifier not to label as positive, a sample that is negative. Similarly we define recall as intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "#### So why do we care about F1 score? ...\n",
    "\n",
    "##### Recall - Catching fraudulent transactions\n",
    "As described above, our model can be 99.83% accurate whilst not catching ANY fraud. Recall determines the amount of the positive class we correctly classify. So we are interested in this as the 'primary' function of the work we are doing: to classify fraud.\n",
    "\n",
    "##### Precision - Not missclassifying non-fraudulent transactions\n",
    "Of course, a model that just classifies everything as fraud is not usable. We want this to be useful and hence we dont want this to happen. So precision is also important.\n",
    "\n",
    "#### Context of the bank\n",
    "In the context of banks and how these metrics add or lose value to them, we indeed care about F1 score. As you can see from the results table for SMOTE, LinearSVC has the highest Recall score, which means it is great at finding true fraudulent cases. However, it's precision is very low at 0.06. This essentially means that the classifier performs badly when it comes to predicting some non-fraudulent data and falsly labelling them as fraud. Why is this bad? This is bad because the loses the bank money and gives customers a bad experience. If we have bad precision then we falsly classify as fraud a lot and we freeze customer cards and accounts and send them a text to say we believe there is fraud etc. Only to ultimately verify that everything is benign and reverse the situation. This is very bad and gives a bad impression for the customer, who may indeed change bank or lose faith in the bank's intelligence systems.\n",
    "\n",
    "#### Hence, we care about F1 score, which is the balance between these two metrics. Recall: being able to catch true frauds and Precision: being able to correctly classify and reduce the number of false positives. Even when we have balanced the dataset through resampling, these metrics are still the quantities we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.\n",
    "## Logistic regression (without sampling)\n",
    "---\n",
    "Let's setup a logistic regression classifier to run on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and classifer instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \n",
    "\n",
    "# Call the logistic regression model\n",
    "lr = LogisticRegression(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign data to x and y and perform a train-test split on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the data in a single run and print a confusion matrix\n",
    "This is just a single run for the purposes of printing a confusion matrix to give us a visualisation of how the classifer performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikitplot library for confusion matrix printing\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "# Import classification report from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109ded10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEWCAYAAADxboUEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111692350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.88      0.62      0.73       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the classifier using the training data\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Print report too\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation\n",
    "\n",
    "So, as we can see, without any sampling techniques on the data, running a simple logistic regression gives us a F1 score average of around 73%. \n",
    "\n",
    "Despite the model being almost perfect for non-fraudluent examples, nearly 40% of fraudlent cases were incorrectly predicted. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aside on C parameter of Logistic regression\n",
    "---\n",
    "The C parameter of the logistic regression is essentially a regularisation parameter. Increasing the regularisation strength penalises \"large\" weight coefficients. This is mainly so that the model performs better on unseen data and avoids learning anomolies or noise.\n",
    "\n",
    "#### To determine the best value to give this parameter we can do a quick hyper-parameter tuning, namely Grid Search, to find the best value to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C parameter found:  \n",
      "\n",
      "{'C': 10} \n",
      "\n",
      "Grid scores on development set: \n",
      "\n",
      "0.695 for {'C': 0.01}\n",
      "0.717 for {'C': 0.1}\n",
      "0.725 for {'C': 1}\n",
      "0.727 for {'C': 10}\n",
      "0.727 for {'C': 100}\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85296\n",
      "          1       0.88      0.62      0.73       147\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = GridSearchCV(LogisticRegression(C = 0.01, random_state=0), {'C':[0.01, 0.1, 1, 10, 100]}, scoring='f1')\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "\n",
    "# # Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print \"Best C parameter found: \", \"\\n\"\n",
    "print lr.best_params_, \"\\n\"\n",
    "\n",
    "print \"Grid scores on development set:\", \"\\n\"\n",
    "\n",
    "means = lr.cv_results_['mean_test_score']\n",
    "\n",
    "for mean, params in zip(means, lr.cv_results_['params']):\n",
    "    print \"%0.3f for %r\"% (mean, params)\n",
    "\n",
    "print \"Detailed classification report:\"\n",
    "\n",
    "print classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we can see here that C=10 is the best value to use, if using the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.\n",
    "## Cross Validation\n",
    "\n",
    "When cross validating using resampling techniques, you have to be careful you are not introducing any bias to the model along the way. These are some of the points addressed in the way cross validation is performed in this project:\n",
    "\n",
    "### - In the case of oversampling and Smote, preserving a test set and resampling only training data\n",
    "\n",
    "It is important we preserve a 'pure' real-life sample of the data for testing, that is not manipulated by resampling. This is important to test the generalisability of the model and ensures that we don't introduce any bias by using resampled data in our testing set. The whole point of validating the model is to test it's performance on unseen data, after all.\n",
    "\n",
    "### - Oversampling inside the cross validation loop\n",
    "\n",
    "A typical approach would perhaps be to simply oversample the data and then pass this onto cross validation. This will introduce bias by allowing oversampled minority class data points to 'leak' into the validation test set of the CV loop. This will therefore give a higher result as the model has already seen these data points. In the case of Oversampling the minority class datapoints are simply duplicated so it is especially important here. This is not the case for SMOTE, which creates synthetic data points but as described before, it is still important to preserve a 'pure' test set.\n",
    "\n",
    "To visualise this, see the following:\n",
    "\n",
    "![caption](cv-oversample-1.jpg)\n",
    "\n",
    "![caption](cv-oversample-2.jpg)\n",
    "\n",
    "Diagrams from https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Test_Train_Split vs Custom cross_val_score using KFold\n",
    "\n",
    "This concerns the underlying approach for the cross validation loop. We have have already seen we can use sklearn's test_train_split function to split the data into train and test portions. We can then oversample our training data, fit the model and make predictions using the test set. \n",
    "\n",
    "#### Approach 1 would be to simply do this multiple times and average the results. \n",
    "\n",
    "This approach, however, will give better results than expected (which will be shown in a later section, I go on to implement this version for comparison). The reason for this is due to the nature of test_train_split and it's randomness. \n",
    "\n",
    "#### Problems with this method:\n",
    "Test_train_split allows you to randomly split your data, by giving a parameter that specifies the ratio. However as the split is random, it is likely that there will be overlap in the CV iterations as to which data points are put in the test set. In other words, values selected during one iteration, could be selected again during another iteration.\n",
    "\n",
    "The consequences of this means that the model may not be exposed to particular portions of the data whereby it does not generalise well and we are not capturing that in our results. Also, It is not making maximal use of the data we have.\n",
    "\n",
    "#### Approach 2 - KFOLD\n",
    "\n",
    "Kfold is a well known cross validation technique whereby instead of random splitting of the data, the data is split equally into N folds. Each iteration then uses N-1 folds for training and the Nth fold for validation. This means that the classifier gets tested on all parts of our data and will capture all variations on performance. It also means we make maximal use of our data. \n",
    "\n",
    "#### Therefore the approach that is used is:\n",
    "* Original dataset -> Cross-Val loop\n",
    "* Cross-Val Loop: N interations of KFOLD technique\n",
    "* Each KFOLD iteration: Oversample the training folds, every time and validate on the preserved test fold\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validating Logistic Regression on Original Dataset\n",
    "\n",
    "This function is the custom cross validation for the original dataset.\n",
    "\n",
    "It uses StratifiedKFold, which is a variation of KFold that ensures there is roughly equal class distribution in the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_original(data, clf, n):\n",
    "    '''\n",
    "        data: the original dataset\n",
    "        clf: the classifier to evaluate\n",
    "        n: the number of iterations and hence splits to be made\n",
    "        \n",
    "        return: List of [name, f1_avg, precision_avg, recall_avg, train_time_avg]\n",
    "    '''\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=0)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X = data.loc[:, data.columns != 'Class']\n",
    "    y = data.loc[:, data.columns == 'Class']\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        \n",
    "        print '='*20\n",
    "        print 'Total training length: ', len(train_index)\n",
    "        print 'Total testing length: ', len(test_index)\n",
    "        \n",
    "        # Clone the classifier for a fresh, independant instance\n",
    "        clone_clf = clone(clf)\n",
    "        \n",
    "        # skfolds gives us indexes of the data, so create the train and test folds using these indexes\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        print 'Training non-fraud count: ', len(y_train_folds[y_train_folds['Class']==0])\n",
    "        print 'Training fraud count: ', len(y_train_folds[y_train_folds['Class']==1])\n",
    "        print 'Testing non-fraud count: ', len(y_test_fold[y_test_fold['Class']==0])\n",
    "        print 'Testing fraud count: ', len(y_test_fold[y_test_fold['Class']==1])\n",
    "        print '='*20\n",
    "        \n",
    "        X_res, y_res = X_train_folds, y_train_folds\n",
    "        \n",
    "        # Start a timer to measure training time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print '\\n Fitting the model... CV[{}]'.format(cv), '\\n'\n",
    "        \n",
    "        # Train / fit the model\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        # Get metric results \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log for original dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for Original dataset results\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log_original = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log_original.set_index('Classifier', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run cross val on original dataset, using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LogisticRegression', 0.67952618651529617, 0.85868002556977541, 0.58536585365853655, datetime.timedelta(0, 2, 101358)])\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "entry = custom_cross_val_original(data, lr, 3)\n",
    "\n",
    "log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "log_original = log_original.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0  LogisticRegression  0.679526    0.85868  0.585366 00:00:02.101358\n"
     ]
    }
   ],
   "source": [
    "print log_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In comparison to before:\n",
    "#### f1 = 0.73 (without cross validation)\n",
    "#### f1 = 0.68 (with cross validation)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Resampling methods\n",
    "\n",
    "## Undersampling \n",
    "---\n",
    "#### Here, we will attempt undersampling by reducing the number of the majority class, down to a 50:50 ratio with the minority class\n",
    "\n",
    "The following is a function that undersamples the dataset, using a random seed that ensures it's the same everytime for validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_data(data):\n",
    "\n",
    "    fraud_indices = np.array(data[data.Class == 1].index)\n",
    "    print 'Number of frauds', len(fraud_indices)\n",
    "\n",
    "    non_fraud = data[data.Class==0]\n",
    "    fraud = data[data.Class==1]\n",
    "\n",
    "    print 'number of non fraud: ', len(non_fraud)\n",
    "    non_fraud = non_fraud.loc[np.random.choice(non_fraud.index, len(fraud_indices), replace=False)]\n",
    "\n",
    "    undersampled_data = pd.concat([non_fraud, fraud])\n",
    "    print 'non_fraud after: ', len(non_fraud)\n",
    "\n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X = undersampled_data.loc[:, data.columns != 'Class']\n",
    "    y = undersampled_data.loc[:, data.columns == 'Class']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single run, with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110e6aad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns9xywJlZbv1/BpFi+rffRYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11117e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94       147\n",
      "          1       0.96      0.91      0.93       149\n",
      "\n",
      "avg / total       0.94      0.94      0.94       296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X,y = undersample_data(data)\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Print report too\n",
    "print classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log for undersample dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for undersample dataset results\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log_under = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log_under.set_index('Classifier', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersample Cross-Val function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_under(data, clf, n):\n",
    "    '''\n",
    "        data: the original dataset\n",
    "        clf: the classifier to evaluate\n",
    "        n: the number of iterations and hence splits to be made\n",
    "        \n",
    "        return: List of [name, f1_avg, precision_avg, recall_avg, train_time_avg]\n",
    "    '''\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=0)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    # Assign variables x and y corresponding to row data and it's class value\n",
    "    X,y = undersample_data(data)\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        \n",
    "        print '='*20\n",
    "        print 'Total training length: ', len(train_index)\n",
    "        print 'Total testing length: ', len(test_index)\n",
    "        \n",
    "        # Clone the classifier for a fresh, independant instance\n",
    "        clone_clf = clone(clf)\n",
    "        \n",
    "        # skfolds gives us indexes of the data, so create the train and test folds using these indexes\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        print 'Training non-fraud count: ', len(y_train_folds[y_train_folds['Class']==0])\n",
    "        print 'Training fraud count: ', len(y_train_folds[y_train_folds['Class']==1])\n",
    "        print 'Testing non-fraud count: ', len(y_test_fold[y_test_fold['Class']==0])\n",
    "        print 'Testing fraud count: ', len(y_test_fold[y_test_fold['Class']==1])\n",
    "        print '='*20\n",
    "        \n",
    "        X_res, y_res = X_train_folds, y_train_folds\n",
    "        \n",
    "        # Start a timer to measure training time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print '\\n Fitting the model... CV[{}]'.format(cv), '\\n'\n",
    "        \n",
    "        # Train / fit the model\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        # Get metric results \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LogisticRegression', 0.92047940226853964, 0.96235388239477315, 0.88211382113821146, datetime.timedelta(0, 0, 5487)])\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "entry = custom_cross_val_under(data, lr, 3)\n",
    "\n",
    "log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "log_under = log_under.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.920479</td>\n",
       "      <td>0.962354</td>\n",
       "      <td>0.882114</td>\n",
       "      <td>00:00:00.005487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.920479   0.962354  0.882114 00:00:00.005487"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.679526</td>\n",
       "      <td>0.85868</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>00:00:02.101358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.679526    0.85868  0.585366 00:00:02.101358"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "#### As we can see, by bringing the data to a 50:50 ratio, we bring the f1 performance up to 92% average! up from 68%.\n",
    "This is a significant increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Oversampling \n",
    "---\n",
    "\n",
    "Next, we want to try oversampling techniques. This is where the minority class (the fraudulent cases) is scaled up in size, to compare more equally with the number of the majority class. \n",
    "\n",
    "Oversampling in particular is duplication of minority class data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A way we can do this is by random oversampling, which randomly duplicates data. Let's see how this performs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_data(x_data, y_data):\n",
    "\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import RandomOverSampler \n",
    "    ros = RandomOverSampler(random_state=1)\n",
    "    X_res, y_res = ros.fit_sample(x_data, y_data)\n",
    "    print('Original dataset shape {}'.format(Counter(data['Class'])))\n",
    "    print('Training dataset shape {}'.format(Counter(y_data['Class'])))\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single run, with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 284315, 1: 492})\n",
      "Resampled training dataset shape Counter({0: 284315, 1: 284315})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111578e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEWCAYAAADxboUEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111692850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95     85172\n",
      "          1       0.98      0.92      0.95     85417\n",
      "\n",
      "avg / total       0.95      0.95      0.95    170589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-assign X and Y values\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X_over,y_over = oversample_data(X,y)\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over,y_over,test_size = 0.3, random_state = 0)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Print report too\n",
    "print classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold on. 0.95 F1 score seems incredibly high. Well, notice that we are oversampling BEFORE splitting. Therefore when testing, the model has seen data before\n",
    "\n",
    "### The proper way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 199019, 1: 345})\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f792c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEWCAYAAADxboUEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111692890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     85296\n",
      "          1       0.06      0.91      0.12       147\n",
      "\n",
      "avg / total       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-assign X and Y values\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "# oversample training only\n",
    "X_over,y_over = oversample_data(X_train,y_train)\n",
    "\n",
    "lr.fit(X_over, y_over)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Print report too\n",
    "print classification_report(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log for oversample dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for oversample dataset results\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log_over = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log_over.set_index('Classifier', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample Cross-Val function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_over(X,y, clf, n):\n",
    "    '''\n",
    "        X: the original dataset X values\n",
    "        y: the original dataset y values\n",
    "        clf: the classifier to evaluate\n",
    "        n: the number of iterations and hence splits to be made\n",
    "        \n",
    "        return: List of [name, f1_avg, precision_avg, recall_avg, train_time_avg]\n",
    "    '''\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=0)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        \n",
    "        print '='*20\n",
    "        print 'Total training length: ', len(train_index)\n",
    "        print 'Total testing length: ', len(test_index)\n",
    "        \n",
    "        # Clone the classifier for a fresh, independant instance\n",
    "        clone_clf = clone(clf)\n",
    "        \n",
    "        # skfolds gives us indexes of the data, so create the train and test folds using these indexes\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        print 'Training non-fraud count: ', len(y_train_folds[y_train_folds['Class']==0])\n",
    "        print 'Training fraud count: ', len(y_train_folds[y_train_folds['Class']==1])\n",
    "        print 'Testing non-fraud count: ', len(y_test_fold[y_test_fold['Class']==0])\n",
    "        print 'Testing fraud count: ', len(y_test_fold[y_test_fold['Class']==1])\n",
    "        print '='*20\n",
    "        \n",
    "        X_res, y_res = oversample_data(X_train_folds, y_train_folds )\n",
    "        \n",
    "        # Start a timer to measure training time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print '\\n Fitting the model... CV[{}]'.format(cv), '\\n'\n",
    "        \n",
    "        # Train / fit the model\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        # Get metric results \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LogisticRegression', 0.11189251125816561, 0.059767462531385873, 0.89227642276422758, datetime.timedelta(0, 3, 679684)])\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "entry = custom_cross_val_over(X, y, lr, 3)\n",
    "\n",
    "log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "log_over = log_over.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.111893</td>\n",
       "      <td>0.059767</td>\n",
       "      <td>0.892276</td>\n",
       "      <td>00:00:03.679684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.111893   0.059767  0.892276 00:00:03.679684"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_over\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.679526</td>\n",
       "      <td>0.85868</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>00:00:02.101358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.679526    0.85868  0.585366 00:00:02.101358"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.920479</td>\n",
       "      <td>0.962354</td>\n",
       "      <td>0.882114</td>\n",
       "      <td>00:00:00.005487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.920479   0.962354  0.882114 00:00:00.005487"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### We can see that by oversampling, at least with the logistic regression classifier, that the precision hits rock bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SMOTE ( Preserving test data - oversampling training data only)\n",
    "---\n",
    "\n",
    "### Now we try the SMOTE method (Synthetic Minority Oversampling Technique). \n",
    "#### This will oversample our minority data in a similar fashion as before, except the new data will be synthetic ones, which means fraudulent data will be slightly modified (i.e noise added, tweak of value etc) to create new examples.\n",
    "\n",
    "#### The procedure is similar to before, sampling training data only to preserve test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_data(x_data, y_data):\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(x_data, y_data)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a27710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEWCAYAAADxboUEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcVmX9//HXmxlFVFDcSEGDClHE\nRECk7GuWhWAW1s8FMkGzLLds+VZuRS6kZSulFiUJmuKWyddQIstKEwQVF9wYF2IQRUQxd4HP749z\nDRymmXvuAzPMzD3vZ4/zmHNf5zrXue6Z/HBd5zrnuhQRmJlZplNrV8DMrC1xUDQzy3FQNDPLcVA0\nM8txUDQzy3FQNDPLcVCsMJK6SPo/SSslXb8R5Rwj6c/NWbfWIOlWSeNaux7WfjgothJJn5U0T9Kr\nkpam/3g/1AxFHwH0ALaPiCM3tJCI+H1EDG+G+qxH0kGSQtJN9dL3Sel3lFnO9yRd1VS+iBgZEVM2\nsLrWATkotgJJXwd+BnyfLIDtBlwKjGqG4t8NPBERq5qhrJbyAvABSdvn0sYBTzTXBZTx/7+tuIjw\ntgk3YBvgVeDIEnk6kwXNZ9P2M6BzOnYQUAt8A1gGLAWOT8fOBd4G3knXOAH4HnBVruzeQADV6fNx\nwFPAf4CngWNy6XfmzvsgMBdYmX5+MHfsDuB84K5Uzp+BHRr5bnX1/xVwSkqrApYA3wXuyOX9ObAY\neAW4F/iflD6i3vd8IFePCakebwDvS2lfSMcvA27Mlf8D4HZArf3/C29tZ/O/pJveB4AtgJtK5Dkb\nGAYMBPYBhgLn5I6/iyy49iQLfJdI6h4R48lan9dGxNYRcXmpikjaCpgIjIyIrmSBb34D+bYD/pTy\nbg/8BPhTvZbeZ4HjgZ2AzYH/LXVtYCowNu0fAjxM9g9A3lyy38F2wNXA9ZK2iIjb6n3PfXLnHAuc\nCHQFFtUr7xvA3pKOk/Q/ZL+7cRHhd11tLQfFTW97YHmU7t4eA5wXEcsi4gWyFuCxuePvpOPvRMQM\nstZSvw2szxpggKQuEbE0IhY0kOcTwMKIuDIiVkXENcBjwCdzeX4XEU9ExBvAdWTBrFER8S9gO0n9\nyILj1AbyXBURL6Zr/pisBd3U97wiIhakc96pV97rZL/HnwBXAadFRG0T5VkH46C46b0I7CCpukSe\nXVi/lbMopa0to15QfR3YumhFIuI14Gjgy8BSSX+StEcZ9amrU8/c5+c2oD5XAqcCH6GBlrOk/5X0\naBpJf5msdbxDE2UuLnUwIuaQ3S4QWfA2W4+D4qZ3N/AWcHiJPM+SDZjU2Y3/7lqW6zVgy9znd+UP\nRsTMiPg4sDNZ6+83ZdSnrk5LNrBOda4ETgZmpFbcWql7+y3gKKB7RGxLdj9TdVVvpMySXWFJp5C1\nOJ9N5Zutx0FxE4uIlWQDCpdIOlzSlpI2kzRS0g9TtmuAcyTtKGmHlL/Jx08aMR84UNJukrYBzqw7\nIKmHpFHp3uJbZN3wNQ2UMQPYPT1GVC3paKA/cMsG1gmAiHga+DDZPdT6ugKryEaqqyV9F+iWO/48\n0LvICLOk3YELgM+RdaO/JalkN986HgfFVpDuj32dbPDkBbIu36nAH1OWC4B5wIPAQ8B9KW1DrjUL\nuDaVdS/rB7JOqR7PAivIAtRJDZTxInAY2UDFi2QtrMMiYvmG1Kle2XdGREOt4JnAbWSP6SwC3mT9\nrnHdg+kvSrqvqeuk2xVXAT+IiAciYiFwFnClpM4b8x2sssgDb2Zm67ilaGaW46BoZpbjoGhmluOg\naGaWU+oB4k1O1V1Cm3dt7WpYAQP33K21q2AFLFr0DC8uX66mczauqtu7I1a9UVbeeOOFmRExYmOu\nt6m1raC4eVc69zuqtathBfz9romtXQUr4MMHDN3oMmLVG2X/d/rm/EuaegOpzWlTQdHM2gNBBc/K\n5qBoZsUI6FTV2rVoMQ6KZlacNuq2ZJvmoGhmBVV297lyv5mZtRypvK3JYvQ1SQskPSzpGklbSOoj\naY6kGknXSto85e2cPtek471z5ZyZ0h+XdEgufURKq5F0RjlfzUHRzIoRWUuxnK1UMVJP4CvAkIgY\nQLYsxWiyZSJ+GhHvA14imyGd9POllP7TlA9J/dN5e5EtVXGppCpJVcAlwEiyWZ3GpLwlOSiaWUFl\nthLLu+9YDXRJsxhtSbbm0EeBG9LxKaybe3RU+kw6frAkpfRpEfFWmo6uhmwJj6FATUQ8FRFvA9Mo\nY3E4B0UzK65TVXlbNsv8vNx2Yl0REbEE+BHwb7JguJJseruXczPL17JuhveepOnj0vGVZMt7rE2v\nd05j6SV5oMXMCio00LI8IoY0WIrUnazl1gd4mWyOzFZ/+8VB0cyKEc31SM7HgKfT4mxI+gNwALCt\npOrUGuzFumUvlgC7ArWpu70N2aTHdel18uc0lt4od5/NrLhmGGgh6zYPS0tyCDgYeAT4G3BEyjMO\nuDntT0+fScf/mpannQ6MTqPTfYC+wD1kS+T2TaPZm5MNxkxvqlJuKZpZQc3znGJEzJF0A9lyG6uA\n+4FJZGuMT5N0QUqrW7/8crLlI2rIls8YncpZIOk6soC6CjglIlYDSDqVbGmLKmByI0v4rsdB0cyK\nEVDVPK/5RcR4YHy95KfIRo7r530TOLKRciYAExpIn0G28FrZHBTNrDi/5mdmVqeyX/NzUDSz4txS\nNDPLcUvRzCwp/xW+dslB0cyK8ySzZmZ1PNBiZrY+d5/NzJK6+RQrlIOimRXk7rOZ2fo80GJmluN7\nimZmidx9NjNbn1uKZmbryEHRzCyTrUbgoGhmlpFQp8oNipV7t9TMWoyksrYmyugnaX5ue0XSVyVt\nJ2mWpIXpZ/eUX5ImSqqR9KCkQbmyxqX8CyWNy6UPlvRQOmeiymjiOiiaWWHNERQj4vGIGBgRA4HB\nwOvATcAZwO0R0Re4PX0GGEm2KFVf4ETgslSX7ciWNNifbBmD8XWBNOX5Yu68JpdQdVA0s8KaIyjW\nczDwZEQsIlsLekpKnwIcnvZHAVMjM5tsKdSdgUOAWRGxIiJeAmYBI9KxbhExO636NzVXVqN8T9HM\nilHayrODpHm5z5MiYlID+UYD16T9HhGxNO0/B/RI+z2BxblzalNaqfTaBtJLclA0s0JEoVbg8ogY\nUrK8bE3mTwFn1j8WESEpitdyw7n7bGaFderUqaytTCOB+yLi+fT5+dT1Jf1cltKXALvmzuuV0kql\n92ogvfR3K7fWZmZ1mvme4hjWdZ0BpgN1I8jjgJtz6WPTKPQwYGXqZs8EhkvqngZYhgMz07FXJA1L\no85jc2U1yt1nMyum2D3F0kVJWwEfB76US74IuE7SCcAi4KiUPgM4FKghG6k+HiAiVkg6H5ib8p0X\nESvS/snAFUAX4Na0leSgaGaFNdcbLRHxGrB9vbQXyUaj6+cN4JRGypkMTG4gfR4woEidHBTNrJCC\nAy3tjoOimRVWya/5OSiaWTHyhBBmZutxUDQzy3FQNDNLPNBiZlZf5cZEB0UzK0gUeYWv3XFQNLPC\n3H02M8ur3JjoCSGKOO2Yj3DvDWcz7/qzmHLhcXTevJrLxn+WOdeewT3XnsnVF5/AVl02B+CAQe/l\nX1d/m//M/Tmf/tjA9cq54CujmHf9Wcy7/iyOGL52RnV+N2EcD9z0HeZdfxa/Gn8M1dX+8zSX2sWL\n+cQhB7PfvgMYOmhvLv3lRABuuvF6hg7am222rOa+e+etd86PL76IffbanUHv35O/zJq53rHVq1fz\noWGDOfIzn9xk36EtaYFJZtuMFv2vTtIISY+n9RHOaPqMtmuXHbfh5DEf5oBjfsiQI79PVadOHHnI\nYL71oz+w/9EXMfToC1n83EucNPrDACxe+hInjr+Sa29b/z+0ER/ai4F77sr+oy/iwGN/xFfHHkzX\nrbYAYNqtc9nn0+cz5Mjv02WLzTj+0x/c5N+zUlVXVzPhoouZe//D3P73f/GbX1/KY48+Qv+9BvD7\naTdwwIcOXC//Y48+wo3XX8s99z3EH6bP4Ounn8rq1avXHr/slxPZvd8em/prtAnlBkQHxXokVQGX\nkM2V1h8YI6l/S11vU6iuqqJL582oqupEly02Z+kLK/nPa2+uPb5F583I3lmHfy9dwcMLn2XNmvXn\nx9zzPe/izvtqWL16Da+/+TYPLVzC8A/uCcDMOx9Zm2/ew4vouVN3rHm8a+edGbhv1irv2rUr/fbY\ng2efXUK/Pfak7+79/iv/n26Zzv878mg6d+5M7959eM9738u8ufcAsKS2lpm3zWDc8Sds0u/Qljgo\nbpihQE1EPBURbwPTyNZYaJeefWElP5t6O0/cej5Pz5rAK6++we2zHwPg19/7HM/85fv0692DS6f9\nvWQ5Dz6RBcEuW2zG9ttuxYeH7E6vd60f/KqrOzHmE0OZ9a9HGinFNsaiRc/w4Pz5DNlv/0bzPLtk\nCT17rZuftGfPXix9Npuf9Ixvfo3zJlxU0SOwTVEnlbW1Ry35V21s3YT1SDpR0jxJ82LVGy1YnY2z\nbdcuHHbQ3ux52HjeM/xstuqyOaMP3Q+AL33vKt4z/Gwee/o5jhg+uGQ5t89+jNvufIS/XfENplx4\nPHMefJrVq9esl+fnZx7NXffVcNf9T7bY9+moXn31VY4dcyQXXfwTunXrVvj8W2fcwg477cS+g0r/\nnSudW4otKCImRcSQiBii6i6tXZ1GfXT/PXjm2RdZ/tKrrFq1hj/+9QGG7dNn7fE1a4LrZ97L4QcP\nLFFK5oeXz2TY6Is47KRfIomF/1629thZJ45kx+5b860f/6FFvkdH9s477/C5MUdw1NGf5VOHf6Zk\n3l169mRJ7bo1j5YsqWXnXXoy5+5/cest/8eAfu/h+LGf5R93/I0vHH9sS1e9bZGD4oZqbN2Edmnx\ncysYuncfumyxGQAfGdqPx59+nvfsusPaPId9+P088czzjRUBQKdOYrtttgJgQN9dGNB3F/5yd9YN\nP+7TH+DjH9yTsWdesfbepDWPiOCUL3+Bfv325NTTv9Zk/kM/8UluvP5a3nrrLZ555mmeqqlhyH5D\n+d753+exJ//Nw48/xe+mXs2BB32E3/7uyk3wDdoOAVJ5W3vUks8pzgX6SupDFgxHA59tweu1qLkP\nL+Kmv9zP3Vd/m1Wr1/DAY7VcfuNd3DbpNLpu1QUJHnpiCV/5/rUADO6/G9f+5Its221LDj1wb875\n8icYfMQENquu4i+TvwrAf159k8+fPWVt9/kXZ43m30tXcMeUbwBw81/nc+Gk21rnC1eY2f+6i2lX\nX8VeA/bmgP2zAZfvnnsBb7/1Ft/8+uksX/4CR37mk+z9/n344//dxp799+LT/+9I9tt3ANXV1fzo\nZ7+gqqqqlb9FW9F8rUBJ2wK/JZsdO4DPA48D1wK9gWeAoyLipbTOys/JliR4HTguIu5L5YwDzknF\nXhARU1L6YNYtRzADOD2aaHGoJVskkg4FfgZUAZMjYkKp/J223Ck69zuqVBZrY5bdPbG1q2AFfPiA\nodx377yNimhbvGv3ePe4X5SV94kfjri31BKnkqYA/4yI36alTrcEzgJWRMRF6VG+7hHx7RRPTiML\nivsDP4+I/SVtB8wDhpAF1nuBwSmQ3gN8BZhDFhQnRkTJdVpa9I2WiJiRKmJmlaKZusaStgEOBI4D\nSE+pvC1pFHBQyjYFuAP4NtnTK1NTS2+2pG3TEqgHAbPqFquSNAsYIekOoFtEzE7pU4HDaWLxKr/m\nZ2aFiOzeeJl2kJR/g2FSRExK+32AF4DfSdqHrIV3OtAjLU8K8BzQI+039kRLqfTaBtJLclA0s8IK\ntBSXl+g+VwODgNMiYo6knwPrvfkWESFpk446tvojOWbW/jTTIzm1QG1EzEmfbyALks+nbjHpZ90z\na4090VIqvVcD6SU5KJpZMWU+jtNUTIyI54DFkureszwYeASYDoxLaeOAm9P+dGCsMsOAlambPRMY\nLqm7pO7AcGBmOvaKpGFp5HpsrqxGuftsZoUINecrjqcBv08jz08Bx5M11q6TdAKwCKh7JGUG2chz\nDdkjOccDRMQKSeeTPQYIcF7doAtwMuseybmVJgZZwEHRzDZAcz2YHRHzyR6lqe/gBvIGcEoj5UwG\nJjeQPo/sGciyOSiaWWHt9RW+cjgomlkx7fgVvnI4KJpZIdm7z5UbFR0UzaywCo6JDopmVlyBN1ra\nHQdFMytG7j6bma1VN59ipXJQNLOC2u+s2uVwUDSzwio4JjoomllB8kCLmdlafk7RzKweB0Uzs5wK\njokOimZWnFuKZmZ1PCGEmdk62SSzlRsVHRTNrLBOFdxU9BotZlZYc6zRkpWjZyQ9JGl+3VKokraT\nNEvSwvSze0qXpImSaiQ9KGlQrpxxKf9CSeNy6YNT+TXp3CZr5aBoZoVIzbaaX52PRMTA3FKoZwC3\nR0Rf4HbWLXs6EuibthOBy7L6aDtgPLA/MBQYXxdIU54v5s4b0VRlGg2KkrqV2sr9tmZWeTqpvG0D\njQKmpP0pwOG59KmRmQ1sm5ZAPQSYFRErIuIlYBYwIh3rFhGz0/ouU3NlNarUPcUFQJA9wF6n7nMA\nu5X7Dc2sshQYaNmhrlucTIqISbnPAfw5LXj/63SsR1qeFOA5oEfa7wkszp1bm9JKpdc2kF5So0Ex\nInZt7JiZdVwiG4Eu0/Jct7ghH4qIJZJ2AmZJeix/MCIiBcxNpqx7ipJGSzor7feSNLhlq2VmbVlz\ndZ8jYkn6uQy4ieye4POp60v6uSxlXwLkG2u9Ulqp9F4NpJf+bk1lkPRL4CPAsSnpdeBXTZ1nZhWq\nzEGWpgZaJG0lqWvdPjAceBiYDtSNII8Dbk7704GxaRR6GLAydbNnAsMldU8DLMOBmenYK5KGpVHn\nsbmyGlXOc4ofjIhBku4HiIgVkjYv4zwzq1DN9JhiD+CmFDyrgasj4jZJc4HrJJ0ALAKOSvlnAIcC\nNWSNs+NhbUw6H5ib8p0XESvS/snAFUAX4Na0lVROUHxHUieyG6JI2h5YU8Z5ZlaBRPM8vB0RTwH7\nNJD+InBwA+kBnNJIWZOByQ2kzwMGFKlXOUHxEuBGYEdJ55JF7XOLXMTMKkuHfs0vIqZKuhf4WEo6\nMiIebtlqmVlbVe7bKu1Vue8+VwHvkHWh/RaMWQfXod99lnQ2cA2wC9mQ9tWSzmzpiplZ26Uyt/ao\nnJbiWGDfiHgdQNIE4H7gwpasmJm1XR19ktml9fJVpzQz64Cy0efWrkXLaTQoSvop2T3EFcACSTPT\n5+Gsex7IzDoaddxJZutGmBcAf8qlz2656phZe9Ahu88RcfmmrIiZtQ8dtvtcR9J7gQlAf2CLuvSI\n2L0F62VmbVgltxTLeebwCuB3ZP9AjASuA65twTqZWRtXyY/klBMUt4yImQAR8WREnEMWHM2sA5Kg\nqpPK2tqjch7JeStNCPGkpC+TzUfWtWWrZWZtWSV3n8sJil8DtgK+QnZvcRvg8y1ZKTNr2yo4JpY1\nIcSctPsf1k00a2YdlFBFv/tc6uHtm0hzKDYkIj7TIjUys7atA8+S88tNVotk3z134645m/yyZh1G\nc8WyDnlPMSJu35QVMbP2QUBVMwZFSVXAPGBJRBwmqQ8wDdgeuBc4NiLeltSZbO3mwcCLwNER8Uwq\n40zgBGA18JW6J2YkjQB+Tjb94W8j4qKm6uO5Ec2ssOZazS85HXg09/kHwE8j4n3AS2TBjvTzpZT+\n05QPSf2B0cBewAjgUklVKdheQvYIYX9gTMpb+ruVXW0zs6S5gqKkXsAngN+mzwI+CtyQskwBDk/7\no9Jn0vGDU/5RwLSIeCsiniZb2Gpo2moi4qmIeJus9Tmqye9Wzi8gVbZzuXnNrHJlyxGUvcTpDpLm\n5bYT6xX3M+BbrFsMb3vg5YhYlT7XAj3Tfk9gMUA6vjLlX5te75zG0ksq593nocDlZM8n7iZpH+AL\nEXFaU+eaWWUq0DVeHhFDGjog6TBgWUTcK+mgZqraRivn4e2JwGHAHwEi4gFJH2nRWplZm9ZM4ywH\nAJ+SdCjZZDPdyAZFtpVUnVqDvcjeoiP93BWolVRN1lB7MZdeJ39OY+mNKqf73CkiFtVLW13GeWZW\ngQRUS2VtpUTEmRHRKyJ6kw2U/DUijgH+BhyRso0Dbk7709Nn0vG/prWgpwOjJXVOI9d9gXvIJsPu\nK6mPpM3TNaY39f3KaSkuTl3oSKM5pwFPlHGemVWoFn5M8dvANEkXkK0HVTe36+XAlZJqyFYEGA0Q\nEQskXQc8AqwCTomI1Vk9dSowk+yRnMkRsaCpi5cTFE8i60LvBjwP/CWlmVkHJDX/a34RcQdwR9p/\nimzkuH6eN4EjGzl/AtncDPXTZwAzitSlnHefl5EispkZdNzX/ACQ9BsaeAc6IuoPrZtZB9FOp0os\nSznd57/k9rcAPs36z/6YWQciaLcTyJajnO7zeksPSLoSuLPFamRmbVuxV/janXJaivX1AXo0d0XM\nrP1Qu12BpWnl3FN8iXX3FDuRDYWf0ZKVMrO2q0MvcZpett6HdU+Br0kPS5pZB1bJQbHkGy0pAM6I\niNVpc0A0syITQrQ75bzmN1/Svi1eEzNrF7IlTsvb2qNSa7TUvZC9LzBX0pPAa2S3FCIiBm2iOppZ\nG9MhF64ie6F6EPCpTVQXM2sHOvJAiwAi4slNVBczaycquKFYMijuKOnrjR2MiJ+0QH3MrM0TnTro\nc4pVwNY036qIZlYBRMdtKS6NiPM2WU3MrH0QVFfwTcUm7ymameV15JbiwZusFmbWrlTyIzmNPl4Z\nESs2ZUXMrP3IljlteitdhraQdI+kByQtkHRuSu8jaY6kGknXpvVVSGuwXJvS50jqnSvrzJT+uKRD\ncukjUlqNpLLmbGinz5ybWWsRWeAoZ2vCW8BHI2IfYCAwQtIw4AfATyPifcBLwAkp/wnASyn9pykf\nkvqTrQ6wFzACuFRSVVpT6hJgJNAfGJPyluSgaGbFKOs+l7OVEplX08fN0hbAR4EbUvoU4PC0Pyp9\nJh0/OE1aMwqYFhFvRcTTQA3ZGi9DgZqIeCoi3gampbwlOSiaWSHZGy1lB8UdJM3LbestY5JadPOB\nZcAs4Eng5fSKMUAt0DPt9yTN+p+OrwS2z6fXO6ex9JI2ZJJZM+vgCgyzLI+IIY0dTEuRDpS0LXAT\nsMdGV24jOSiaWWHNPfgcES9L+hvwAWDb3IQ0vVg3n+sSYFegVlI1sA3wYi69Tv6cxtIb5e6zmRVU\n3lyKTc2nKGnH1EJEUhfg48CjwN+AI1K2ccDNaX96+kw6/tc0x+t0YHQane4D9CWb0GYu0DeNZm9O\nNhgzvalv55aimRVSN/rcDHYGpqRR4k7AdRFxi6RHgGmSLgDuBy5P+S8HrpRUQ7YsymiAiFgg6Trg\nEWAVcErqliPpVGAm2WvLkyNiQVOVclA0s8Ka4+HtiHiQbL7W+ulPkY0c109/EziykbImABMaSJ8B\nzChSLwdFMytGtNulBsrhoGhmhTRj97lNclA0s8LcUjQzy6nckOigaGYFCahyS9HMbJ0KjokOimZW\nlFAFd6AdFM2sMLcUzcyS7JGcyo2KDopmVkwZs2q3Zw6KZlZYJa/R4qBoZoVkk8y2di1ajoOimRXm\n0Wczs5wK7j1X9HvdreJLX/g8u+2yE4MHDlibdua3v8k+A/Zgv33fz1FHfJqXX365FWtoDf2Nzh3/\nHfbb9/3sP3ggh40czrPPPgvAP/5+Bz2234b9Bw9k/8ED+f4F57VWtdsUlfm/9qjFgqKkyZKWSXq4\npa7RFh077jhuvuW29dIO/tjHuXf+w8y9/0H69t2di39wYSvVzqDhv9HXvvFN5t7/IHPunc/IQw/j\nwlzwO+BD/8Oce+cz5975nHXOdzd1dducunuK5WztUUu2FK8gW4O1Q/nQ/xzIdtttt17axz4+nOrq\n7E7F0P2HsaS2tjWqZklDf6Nu3bqt3X/99dcqehaYjVbmSn7tdYS6xYJiRPyDbMpwy5l6xWQOGTGy\ntathDRj/nbN5X59dmXbN7/nO99a1FOfMvpuhg/Zh1GEjeWRBk7PZdwgqcytZhrSrpL9JekTSAkmn\np/TtJM2StDD97J7SJWmipBpJD0oalCtrXMq/UNK4XPpgSQ+lcyaqjH/tWv2eoqQT69aEfWH5C61d\nnRb1gwsnUFVdzejPHtPaVbEGnHv+BGqeXszoMcfwq0t/CcDAfQfx+JOLuOe+BzjplNM46ojDmyil\n8hVc97mUVcA3IqI/MAw4RVJ/4Azg9ojoC9yePgOMJFuUqi9wInAZZEEUGA/sT7aMwfi6QJryfDF3\nXpO911YPihExKSKGRMSQHXfYsbWr02KunHIFM/50C1dM/b27Zm3c0WOO4Y833Qhk3eqtt94agBEj\nD+Wdd95h+fLlrVm9NqE5WooRsTQi7kv7/yFbya8nMAqYkrJNAer+JRoFTI3MbLKlUHcGDgFmRcSK\niHgJmAWMSMe6RcTstOrf1FxZjWr1oNgR/Hnmbfzkxz/khpums+WWW7Z2dawBNQsXrt2/ZfrN7N4v\nW5P9ueeeI/vvCebecw9r1qxh++23b5U6tinNERXzxUm9yRaxmgP0iIil6dBzQI+03xNYnDutNqWV\nSq9tIL0kP6fYzMZ+bgz//PsdLF++nPf27sV3vnsuF//wQt566y0OG/FxIBts+cWlv2rlmnZcDf2N\nbrttBgufeJxO6sRu7343Ey/J/j433XgDv5l0GdVV1WzRpQtTr5rmlj6FXvPbQdK83OdJETEpn0HS\n1sCNwFcj4pX87zciQlJsbH2LaLGgKOka4CCyX0otMD4iLi99Vvs39apr/ivtuM+f0Ao1scYU+Rud\ndMqpnHTKqS1dpXanwD8LyyNiSKPlSJuRBcTfR8QfUvLzknaOiKWpC7wspS8Bds2d3iulLSGLNfn0\nO1J6rwbyl9SSo89jImLniNgsInp1hIBo1mE0Q/c5jQRfDjwaET/JHZoO1I0gjwNuzqWPTaPQw4CV\nqZs9ExguqXsaYBkOzEzHXpE0LF1rbK6sRrn7bGaFZPGuWW4hHAAcCzwkaX5KOwu4CLhO0gnAIuCo\ndGwGcChQA7wOHA8QESsknQ8DFJRJAAAHT0lEQVTMTfnOi4i6xwFPJntmugtwa9pKclA0s2KaaT7F\niLiTxtuTBzeQP4BTGilrMjC5gfR5wID/PqNxDopmVlglDzU5KJpZQaroEXgHRTMrrIJjooOimRVT\n8LnsdsdB0cyKq+Co6KBoZoW11wlky+GgaGaF+Z6imVkdr/tsZrY+d5/NzBLhlqKZ2XoqOCY6KJrZ\nBqjgqOigaGaFtdeV+srhoGhmhVVuSHRQNLMNUcFR0UHRzAppxklm2yQHRTMrxg9vm5mtr4Jjotd9\nNrOisklmy9maLEmaLGmZpIdzadtJmiVpYfrZPaVL0kRJNZIelDQod864lH+hpHG59MGSHkrnTFQZ\nlXJQNLPCpPK2MlwBjKiXdgZwe0T0BW5PnwFGAn3TdiJwWVYXbQeMB/YHhgLj6wJpyvPF3Hn1r/Vf\nHBTNrJByVzctJyZGxD+AFfWSRwFT0v4U4PBc+tTIzAa2TetCHwLMiogVEfESMAsYkY51i4jZadGr\nqbmyGuV7imZWXPk3FXeQNC/3eVJETGrinB5pzWaA54Aeab8nsDiXrzallUqvbSC9JAdFMyuswCM5\nyyNiyIZeJyJCUmzo+RvC3WczK6wZ7yk25PnU9SX9XJbSlwC75vL1Smml0ns1kF6Sg6KZFSPoVOa2\ngaYDdSPI44Cbc+lj0yj0MGBl6mbPBIZL6p4GWIYDM9OxVyQNS6POY3NlNcrdZzPbAM3zpKKka4CD\nyO491pKNIl8EXCfpBGARcFTKPgM4FKgBXgeOB4iIFZLOB+amfOdFRN3gzclkI9xdgFvTVpKDopkV\n0pyTzEbEmEYOHdxA3gBOaaScycDkBtLnAQOK1MlB0cwKq+Q3WhwUzawwv/tsZpZTzit87ZWDopkV\nVrkh0UHRzArayGcQ2zwHRTMrzJPMmpnlVW5MdFA0s+IqOCY6KJpZUfISp2ZmdZrzjZa2yBNCmJnl\nuKVoZoVVckvRQdHMCvMjOWZmdfzwtpnZOpU+0OKgaGaFuftsZpbjlqKZWU4Fx0QHRTPbABUcFR0U\nzawQQUW/5qdsLZi2QdILZKt3VZodgOWtXQkrpFL/Zu+OiB03pgBJt5H9fsqxPCJGbMz1NrU2FRQr\nlaR5ETGkteth5fPfrOPyu89mZjkOimZmOQ6Km8ak1q6AFea/WQfle4pmZjluKZqZ5TgompnlOCi2\nIEkjJD0uqUbSGa1dH2uapMmSlkl6uLXrYq3DQbGFSKoCLgFGAv2BMZL6t26trAxXAO3qYWNrXg6K\nLWcoUBMRT0XE28A0YFQr18maEBH/AFa0dj2s9TgotpyewOLc59qUZmZtmIOimVmOg2LLWQLsmvvc\nK6WZWRvmoNhy5gJ9JfWRtDkwGpjeynUysyY4KLaQiFgFnArMBB4FrouIBa1bK2uKpGuAu4F+kmol\nndDadbJNy6/5mZnluKVoZpbjoGhmluOgaGaW46BoZpbjoGhmluOg2I5IWi1pvqSHJV0vacuNKOsg\nSbek/U+VmsVH0raSTt6Aa3xP0v+Wm14vzxWSjihwrd6e2caag4Ni+/JGRAyMiAHA28CX8weVKfw3\njYjpEXFRiSzbAoWDoll75KDYfv0TeF9qIT0uaSrwMLCrpOGS7pZ0X2pRbg1r53d8TNJ9wGfqCpJ0\nnKRfpv0ekm6S9EDaPghcBLw3tVIvTvm+KWmupAclnZsr62xJT0i6E+jX1JeQ9MVUzgOSbqzX+v2Y\npHmpvMNS/ipJF+eu/aWN/UWa5TkotkOSqsnmaXwoJfUFLo2IvYDXgHOAj0XEIGAe8HVJWwC/AT4J\nDAbe1UjxE4G/R8Q+wCBgAXAG8GRqpX5T0vB0zaHAQGCwpAMlDSZ7nXEgcCiwXxlf5w8RsV+63qNA\n/g2S3ukanwB+lb7DCcDKiNgvlf9FSX3KuI5ZWapbuwJWSBdJ89P+P4HLgV2ARRExO6UPI5vU9i5J\nAJuTvba2B/B0RCwEkHQVcGID1/goMBYgIlYDKyV1r5dneNruT5+3JguSXYGbIuL1dI1y3vUeIOkC\nsi761mSvRda5LiLWAAslPZW+w3Dg/bn7jdukaz9RxrXMmuSg2L68ERED8wkp8L2WTwJmRcSYevnW\nO28jCbgwIn5d7xpf3YCyrgAOj4gHJB0HHJQ7Vv8d1EjXPi0i8sETSb034Npm/8Xd58ozGzhA0vsA\nJG0laXfgMaC3pPemfGMaOf924KR0bpWkbYD/kLUC68wEPp+7V9lT0k7AP4DDJXWR1JWsq96UrsBS\nSZsBx9Q7dqSkTqnO7wEeT9c+KeVH0u6StirjOmZlcUuxwkTEC6nFdY2kzin5nIh4QtKJwJ8kvU7W\n/e7aQBGnA5PS7DCrgZMi4m5Jd6VHXm5N9xX3BO5OLdVXgc9FxH2SrgUeAJaRTZ/WlO8Ac4AX0s98\nnf4N3AN0A74cEW9K+i3Zvcb7lF38BeDw8n47Zk3zLDlmZjnuPpuZ5TgompnlOCiameU4KJqZ5Tgo\nmpnlOCiameU4KJqZ5fx/KcycF8ZFdWMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110a27050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     85296\n",
      "          1       0.06      0.92      0.11       147\n",
      "\n",
      "avg / total       1.00      0.98      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-assign X and Y values\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']\n",
    "\n",
    "# Call the logistic regression model with a certain C parameter\n",
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "# Whole dataset, training-test data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "# oversample training only\n",
    "X_smote,y_smote = smote_data(X_train,y_train)\n",
    "\n",
    "lr.fit(X_smote, y_smote)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Print report too\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create log for smote dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for smote dataset results\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log_smote = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log_smote.set_index('Classifier', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smote Cross-Val function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_smote(X,y, clf, n):\n",
    "    '''\n",
    "        X: the original dataset X values\n",
    "        y: the original dataset y values\n",
    "        clf: the classifier to evaluate\n",
    "        n: the number of iterations and hence splits to be made\n",
    "        \n",
    "        return: List of [name, f1_avg, precision_avg, recall_avg, train_time_avg]\n",
    "    '''\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.base import clone\n",
    "    import datetime\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    print 'Cross validating... \\n'\n",
    "    skfolds = StratifiedKFold(n_splits=n, random_state=0)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    cv = 0\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        cv=cv+1\n",
    "        \n",
    "        print '='*20\n",
    "        print 'Total training length: ', len(train_index)\n",
    "        print 'Total testing length: ', len(test_index)\n",
    "        \n",
    "        # Clone the classifier for a fresh, independant instance\n",
    "        clone_clf = clone(clf)\n",
    "        \n",
    "        # skfolds gives us indexes of the data, so create the train and test folds using these indexes\n",
    "        X_train_folds = X.iloc[train_index]\n",
    "        y_train_folds = y.iloc[train_index]\n",
    "        X_test_fold = X.iloc[test_index]\n",
    "        y_test_fold = y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        print 'Training non-fraud count: ', len(y_train_folds[y_train_folds['Class']==0])\n",
    "        print 'Training fraud count: ', len(y_train_folds[y_train_folds['Class']==1])\n",
    "        print 'Testing non-fraud count: ', len(y_test_fold[y_test_fold['Class']==0])\n",
    "        print 'Testing fraud count: ', len(y_test_fold[y_test_fold['Class']==1])\n",
    "        print '='*20\n",
    "        \n",
    "        X_res, y_res = smote_data(X_train_folds, y_train_folds )\n",
    "        \n",
    "        # Start a timer to measure training time\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        print '\\n Fitting the model... CV[{}]'.format(cv), '\\n'\n",
    "        \n",
    "        # Train / fit the model\n",
    "        clone_clf.fit(X_res, y_res)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "        elapsed_times.append(elapsed)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = clone_clf.predict(X_test_fold)\n",
    "        \n",
    "        # Get metric results \n",
    "        prfs = precision_recall_fscore_support(y_test_fold, y_pred, pos_label=1, average='binary')\n",
    "        \n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        \n",
    "        \n",
    "    \n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    print('Mean scores: ', entry )\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LogisticRegression', 0.106678924554976, 0.056838865169851059, 0.88414634146341464, datetime.timedelta(0, 3, 850433)])\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10, random_state=0)\n",
    "\n",
    "entry = custom_cross_val_smote(X, y, lr, 3)\n",
    "\n",
    "log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "log_smote = log_smote.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.106679</td>\n",
       "      <td>0.056839</td>\n",
       "      <td>0.884146</td>\n",
       "      <td>00:00:03.850433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  F1 Score  Precision    Recall   Training Time\n",
       "0  LogisticRegression  0.106679   0.056839  0.884146 00:00:03.850433"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "#### The smote results for Logistic Regression are similar to that of Oversample but slightly less. This if to be expected if you think that oversampling duplicates data points so there is likely to be some slight bias in the model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other classifiers\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    MLPClassifier(random_state=0),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classifiers - original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.77395290958509344, 0.83421045185751075, 0.73373983739837401, datetime.timedelta(0, 0, 662762)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LinearSVC', 0.76050419153705084, 0.88879100595687566, 0.69105691056910568, datetime.timedelta(0, 44, 774054)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.62142741188424722, 0.55098026296856706, 0.73170731707317083, datetime.timedelta(0, 11, 12837)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:59: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.79690943455148411, 0.87134911300597873, 0.74593495934959353, datetime.timedelta(0, 11, 340366)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['MLPClassifier', 0.76678021650346373, 0.84642881579688789, 0.71341463414634143, datetime.timedelta(0, 8, 64149)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['GaussianNB', 0.11407678782227487, 0.061254756941155897, 0.83333333333333337, datetime.timedelta(0, 0, 106360)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.679526   0.858680  0.585366 00:00:02.101358\n",
      "0    KNeighborsClassifier  0.773953   0.834210  0.733740 00:00:00.662762\n",
      "0               LinearSVC  0.760504   0.888791  0.691057 00:00:44.774054\n",
      "0  DecisionTreeClassifier  0.621427   0.550980  0.731707 00:00:11.012837\n",
      "0  RandomForestClassifier  0.796909   0.871349  0.745935 00:00:11.340366\n",
      "0           MLPClassifier  0.766780   0.846429  0.713415 00:00:08.064149\n",
      "0              GaussianNB  0.114077   0.061255  0.833333 00:00:00.106360\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_original(data, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log_original = log_original.append(log_entry)\n",
    "\n",
    "print 'Cross validation training results: '\n",
    "print log_original \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classifiers - Undersampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.92110554698435509, 0.96653839601559299, 0.88008130081300806, datetime.timedelta(0, 0, 1130)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:58: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LinearSVC', 0.91130163866537617, 0.95980609973650177, 0.86788617886178854, datetime.timedelta(0, 0, 16482)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.90231228770569372, 0.90054622236315318, 0.90447154471544711, datetime.timedelta(0, 0, 9130)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:58: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.93284593178038122, 0.97800062969782475, 0.89227642276422758, datetime.timedelta(0, 0, 38412)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['MLPClassifier', 0.92358531486815532, 0.96694577872660059, 0.88414634146341464, datetime.timedelta(0, 0, 514095)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "Number of frauds 492\n",
      "number of non fraud:  284315\n",
      "non_fraud after:  492\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  656\n",
      "Total testing length:  328\n",
      "Training non-fraud count:  328\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  164\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['GaussianNB', 0.91255705221472949, 0.97016697164955135, 0.86178861788617889, datetime.timedelta(0, 0, 1051)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.920479   0.962354  0.882114 00:00:00.005487\n",
      "0    KNeighborsClassifier  0.921106   0.966538  0.880081 00:00:00.001130\n",
      "0               LinearSVC  0.911302   0.959806  0.867886 00:00:00.016482\n",
      "0  DecisionTreeClassifier  0.902312   0.900546  0.904472 00:00:00.009130\n",
      "0  RandomForestClassifier  0.932846   0.978001  0.892276 00:00:00.038412\n",
      "0           MLPClassifier  0.923585   0.966946  0.884146 00:00:00.514095\n",
      "0              GaussianNB  0.912557   0.970167  0.861789 00:00:00.001051\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_under(data, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log_under = log_under.append(log_entry)\n",
    "\n",
    "print 'Cross validation training results: '\n",
    "print log_under \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classifiers - Oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Norm_Amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Norm_Amount        V1        V2        V3        V4        V5        V6  \\\n",
       "0     0.244964 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    -0.342475  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2     1.160686 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3     0.140534 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4    -0.073403 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9    ...          V19       V20       V21  \\\n",
       "0  0.239599  0.098698  0.363787    ...     0.403993  0.251412 -0.018307   \n",
       "1 -0.078803  0.085102 -0.255425    ...    -0.145783 -0.069083 -0.225775   \n",
       "2  0.791461  0.247676 -1.514654    ...    -2.261857  0.524980  0.247998   \n",
       "3  0.237609  0.377436 -1.387024    ...    -1.232622 -0.208038 -0.108300   \n",
       "4  0.592941 -0.270533  0.817739    ...     0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.6343915153694667, 0.5638557937426395, 0.79878048780487809, datetime.timedelta(0, 1, 676455)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LinearSVC', 0.1183838368678225, 0.06352545592049641, 0.87398373983739841, datetime.timedelta(0, 82, 664271)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.6620981115925747, 0.67401075863856852, 0.68089430894308933, datetime.timedelta(0, 8, 96279)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.78819198442693017, 0.87821663818101514, 0.72560975609756095, datetime.timedelta(0, 10, 960490)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['MLPClassifier', 0.6516383681633332, 0.60432989587166241, 0.75406504065040647, datetime.timedelta(0, 29, 25202)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189543, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Original dataset shape Counter({0: 284315, 1: 492})\n",
      "Training dataset shape Counter({0: 189544, 1: 328})\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['GaussianNB', 0.10059091425113059, 0.053460583826191954, 0.85569105691056901, datetime.timedelta(0, 0, 198113)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.111893   0.059767  0.892276 00:00:03.679684\n",
      "0    KNeighborsClassifier  0.634392   0.563856  0.798780 00:00:01.676455\n",
      "0               LinearSVC  0.118384   0.063525  0.873984 00:01:22.664271\n",
      "0  DecisionTreeClassifier  0.662098   0.674011  0.680894 00:00:08.096279\n",
      "0  RandomForestClassifier  0.788192   0.878217  0.725610 00:00:10.960490\n",
      "0           MLPClassifier  0.651638   0.604330  0.754065 00:00:29.025202\n",
      "0              GaussianNB  0.100591   0.053461  0.855691 00:00:00.198113\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_over(X,y, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log_over = log_over.append(log_entry)\n",
    "\n",
    "print 'Cross validation training results: '\n",
    "print log_over\n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classifiers - Smote dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['KNeighborsClassifier', 0.49989361707641011, 0.37501024833826407, 0.83130081300812997, datetime.timedelta(0, 1, 611113)])\n",
      "==============================\n",
      "LinearSVC\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['LinearSVC', 0.11848711154393209, 0.063613872551357378, 0.86991869918699194, datetime.timedelta(0, 81, 473453)])\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['DecisionTreeClassifier', 0.42917422641871833, 0.30650026459799801, 0.74390243902439013, datetime.timedelta(0, 22, 480496)])\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['RandomForestClassifier', 0.79652852057655743, 0.82731469434565963, 0.7804878048780487, datetime.timedelta(0, 21, 439986)])\n",
      "==============================\n",
      "MLPClassifier\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['MLPClassifier', 0.63332715948995022, 0.604771450706171, 0.7357723577235773, datetime.timedelta(0, 25, 657220)])\n",
      "==============================\n",
      "GaussianNB\n",
      "Cross validating... \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[1] \n",
      "\n",
      "====================\n",
      "Total training length:  189871\n",
      "Total testing length:  94936\n",
      "Training non-fraud count:  189543\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94772\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189543, 1: 189543})\n",
      "\n",
      " Fitting the model... CV[2] \n",
      "\n",
      "====================\n",
      "Total training length:  189872\n",
      "Total testing length:  94935\n",
      "Training non-fraud count:  189544\n",
      "Training fraud count:  328\n",
      "Testing non-fraud count:  94771\n",
      "Testing fraud count:  164\n",
      "====================\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 189544, 1: 189544})\n",
      "\n",
      " Fitting the model... CV[3] \n",
      "\n",
      "('Mean scores: ', ['GaussianNB', 0.10714786826907374, 0.05718309279136391, 0.85569105691056901, datetime.timedelta(0, 0, 202958)])\n",
      "==============================\n",
      "Cross validation training results: \n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.106679   0.056839  0.884146 00:00:03.850433\n",
      "0    KNeighborsClassifier  0.499894   0.375010  0.831301 00:00:01.611113\n",
      "0               LinearSVC  0.118487   0.063614  0.869919 00:01:21.473453\n",
      "0  DecisionTreeClassifier  0.429174   0.306500  0.743902 00:00:22.480496\n",
      "0  RandomForestClassifier  0.796529   0.827315  0.780488 00:00:21.439986\n",
      "0           MLPClassifier  0.633327   0.604771  0.735772 00:00:25.657220\n",
      "0              GaussianNB  0.107148   0.057183  0.855691 00:00:00.202958\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*30)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "\n",
    "    entry = custom_cross_val_smote(X,y, clf, 3)\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log_smote = log_smote.append(log_entry)\n",
    "\n",
    "print 'Cross validation training results: '\n",
    "print log_smote\n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.679526   0.858680  0.585366 00:00:02.101358\n",
      "0    KNeighborsClassifier  0.773953   0.834210  0.733740 00:00:00.662762\n",
      "0               LinearSVC  0.760504   0.888791  0.691057 00:00:44.774054\n",
      "0  DecisionTreeClassifier  0.621427   0.550980  0.731707 00:00:11.012837\n",
      "0  RandomForestClassifier  0.796909   0.871349  0.745935 00:00:11.340366\n",
      "0           MLPClassifier  0.766780   0.846429  0.713415 00:00:08.064149\n",
      "0              GaussianNB  0.114077   0.061255  0.833333 00:00:00.106360 \n",
      "\n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.920479   0.962354  0.882114 00:00:00.005487\n",
      "0    KNeighborsClassifier  0.921106   0.966538  0.880081 00:00:00.001130\n",
      "0               LinearSVC  0.911302   0.959806  0.867886 00:00:00.016482\n",
      "0  DecisionTreeClassifier  0.902312   0.900546  0.904472 00:00:00.009130\n",
      "0  RandomForestClassifier  0.932846   0.978001  0.892276 00:00:00.038412\n",
      "0           MLPClassifier  0.923585   0.966946  0.884146 00:00:00.514095\n",
      "0              GaussianNB  0.912557   0.970167  0.861789 00:00:00.001051 \n",
      "\n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.111893   0.059767  0.892276 00:00:03.679684\n",
      "0    KNeighborsClassifier  0.634392   0.563856  0.798780 00:00:01.676455\n",
      "0               LinearSVC  0.118384   0.063525  0.873984 00:01:22.664271\n",
      "0  DecisionTreeClassifier  0.662098   0.674011  0.680894 00:00:08.096279\n",
      "0  RandomForestClassifier  0.788192   0.878217  0.725610 00:00:10.960490\n",
      "0           MLPClassifier  0.651638   0.604330  0.754065 00:00:29.025202\n",
      "0              GaussianNB  0.100591   0.053461  0.855691 00:00:00.198113 \n",
      "\n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.106679   0.056839  0.884146 00:00:03.850433\n",
      "0    KNeighborsClassifier  0.499894   0.375010  0.831301 00:00:01.611113\n",
      "0               LinearSVC  0.118487   0.063614  0.869919 00:01:21.473453\n",
      "0  DecisionTreeClassifier  0.429174   0.306500  0.743902 00:00:22.480496\n",
      "0  RandomForestClassifier  0.796529   0.827315  0.780488 00:00:21.439986\n",
      "0           MLPClassifier  0.633327   0.604771  0.735772 00:00:25.657220\n",
      "0              GaussianNB  0.107148   0.057183  0.855691 00:00:00.202958 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print log_original, '\\n'\n",
    "print log_under, '\\n'\n",
    "print log_over, '\\n'\n",
    "print log_smote, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging runs - the wrong way to validate\n",
    "\n",
    "#### Here, we simply perform a test train split and train the model, averaging 3 times to get results. This is to show the difference in results if we do it this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_sample(x_data, y_data): \n",
    "    ''' 1) Generate new, random train-test split\n",
    "        2) Random smote oversample the train data, keeping test data unseen\n",
    "        3) Use this new train-test split to fit and test model\n",
    "    '''\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data,y_data,test_size = 0.3)\n",
    "\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X_res, y_res = sm.fit_sample(X_train, y_train)\n",
    "    print('Resampling the data with SMOTE. . .')\n",
    "    print('Resampled training dataset shape {}'.format(Counter(y_res)))\n",
    "\n",
    "    return X_res, y_res, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables x and y corresponding to row data and it's class value\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( log_original , open( \"baseline_log_original.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( log_under , open( \"baseline_log_under.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( log_over , open( \"baseline_log_over.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( log_smote , open( \"baseline_log_smote.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "LogisticRegression\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199018, 1: 199018})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199008, 1: 199008})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199025, 1: 199025})\n",
      "==============================\n",
      "==============================\n",
      "KNeighborsClassifier\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199012, 1: 199012})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199028, 1: 199028})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199029, 1: 199029})\n",
      "==============================\n",
      "==============================\n",
      "LinearSVC\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199024, 1: 199024})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199029, 1: 199029})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199019, 1: 199019})\n",
      "==============================\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199034, 1: 199034})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199036, 1: 199036})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199027, 1: 199027})\n",
      "==============================\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199008, 1: 199008})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarryG1/Documents/University/Year_3/DeepLearning-CreditCardFraud/devEnv/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199010, 1: 199010})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199023, 1: 199023})\n",
      "==============================\n",
      "==============================\n",
      "MLPClassifier\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199029, 1: 199029})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199011, 1: 199011})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199007, 1: 199007})\n",
      "==============================\n",
      "==============================\n",
      "GaussianNB\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199013, 1: 199013})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199033, 1: 199033})\n",
      "Resampling the data with SMOTE. . .\n",
      "Resampled training dataset shape Counter({0: 199025, 1: 199025})\n",
      "==============================\n",
      "Cross validation training results: \n",
      "               Classifier  F1 Score  Precision    Recall   Training Time\n",
      "0      LogisticRegression  0.711097   0.849243  0.612047 00:00:01.661159\n",
      "0    KNeighborsClassifier  0.846665   0.950516  0.763758 00:00:00.692843\n",
      "0               LinearSVC  0.798250   0.891613  0.723210 00:00:49.479348\n",
      "0  DecisionTreeClassifier  0.941819   0.954909  0.929109 00:00:09.491732\n",
      "0  RandomForestClassifier  0.932806   0.992030  0.880539 00:00:12.129519\n",
      "0           MLPClassifier  0.867500   0.963761  0.789322 00:00:10.706168\n",
      "0              GaussianNB  0.122036   0.065706  0.856953 00:00:00.100451\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Setting up dataframe table properties\n",
    "log_cols=[\"Classifier\", \"F1 Score\", \"Precision\", \"Recall\", \"Training Time\"]\n",
    "log_avg = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "# Replace table index by the Classifier column\n",
    "log_avg.set_index('Classifier', inplace=True)\n",
    "\n",
    "# Loop over the classifiers, fit the data over 3 iterations, gather results, input to dataframe table\n",
    "for clf in classifiers:\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1score = []\n",
    "    elapsed_times = []\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(name)\n",
    "    for i in range(3):\n",
    "        X_res, y_res, X_test, y_test = generate_train_test_sample(X, y)\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "        clf.fit(X_train, y_train)\n",
    "        end = datetime.datetime.now()\n",
    "        elapsed = end - start\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        prfs = precision_recall_fscore_support(y_test, y_pred, pos_label=1, average='binary')\n",
    "\n",
    "        precision.append(prfs[0])\n",
    "        recall.append(prfs[1])\n",
    "        f1score.append(prfs[2])\n",
    "        elapsed_times.append(elapsed)\n",
    "\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    average_timedelta = sum(elapsed_times, datetime.timedelta(0)) / len(elapsed_times)\n",
    "    entry = [name, np.mean(f1score), np.mean(precision), np.mean(recall), average_timedelta]\n",
    "    log_entry = pd.DataFrame([entry], columns=log_cols)\n",
    "    log_avg = log_avg.append(log_entry)\n",
    "\n",
    "\n",
    "print 'Cross validation training results: '\n",
    "print log_avg \n",
    "\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAJQCAYAAAC0KqwEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111218d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = log_smote.plot(x=\"Classifier\", y=\"F1 Score\", kind=\"bar\", figsize=(8,8), legend=False)\n",
    "plt.show()\n",
    "\n",
    "log_original.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAJQCAYAAAC0KqwEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f7cbad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_original.plot(x=\"Classifier\", y=[\"F1 Score\", \"Precision\", \"Recall\"], kind=\"bar\", figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAJQCAYAAAC0KqwEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nliSpZwxnSZJ65v8D/4S+IhUoCFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f7cf890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_under.plot(x=\"Classifier\", y=[\"F1 Score\", \"Precision\", \"Recall\"], kind=\"bar\", figsize=(8,8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAJQCAYAAAC0KqwEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB7KiXzQ/4ZNTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109cce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_over.plot(x=\"Classifier\", y=[\"F1 Score\", \"Precision\", \"Recall\"], kind=\"bar\", figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAJQCAYAAAC0KqwEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1113d6450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_smote.plot(x=\"Classifier\", y=[\"F1 Score\", \"Precision\", \"Recall\"], kind=\"bar\", figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking RandomForest and tuning for best possible result\n",
    "\n",
    "An overall majority classifier that appears to be most suited to this problem is the Random Forest Classifier. This classifier can maintain precision the best when resampling the data, to leave a respectable F1-score. Here, we take this classifier as the most suited and fine tune it to try and squeeze the best possible result..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning three prominent parameters:\n",
    "#### n_estimators={10, 100,200},  criterion={'gini', entropy}, max_features={'auto',log2}\n",
    "\n",
    "Code in custom-cv-runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[['RandomForestClassifier', 0.80310735939302502, 0.84838839253169562, 0.77439024390243905, datetime.timedelta(0, 22, 854772)], \n",
    " ['RandomForestClassifier', 0.80134412203377714, 0.83486871215963909, 0.78455284552845528, datetime.timedelta(0, 17, 443312)], \n",
    " ['RandomForestClassifier', 0.77542214632977435, 0.78594378789614616, 0.7825203252032521, datetime.timedelta(0, 20, 505811)], \n",
    " ['RandomForestClassifier', 0.81534391534391537, 0.85003931074672978, 0.79674796747967491, datetime.timedelta(0, 18, 527809)], \n",
    " ['RandomForestClassifier', 0.81697793752433112, 0.85946782785879117, 0.79065040650406504, datetime.timedelta(0, 219, 242425)], \n",
    " ['RandomForestClassifier', 0.82194169531860661, 0.84974358974358977, 0.80691056910569114, datetime.timedelta(0, 214, 48315)], \n",
    " ['RandomForestClassifier', 0.82153339873196618, 0.85130515130515139, 0.80487804878048796, datetime.timedelta(0, 176, 436813)], \n",
    " ['RandomForestClassifier', 0.81766738578277387, 0.85984426820475834, 0.79065040650406504, datetime.timedelta(0, 227, 616945)], \n",
    " ['RandomForestClassifier', 0.82211208035950312, 0.85931385274873762, 0.79878048780487809, datetime.timedelta(0, 436, 84050)], \n",
    " ['RandomForestClassifier', 0.82702497937955, 0.85378202383278534, 0.81300813008130079, datetime.timedelta(0, 419, 267422)], \n",
    " ['RandomForestClassifier', 0.82550831970847571, 0.85240555881777258, 0.8109756097560975, datetime.timedelta(0, 345, 739678)], \n",
    " ['RandomForestClassifier', 0.81691409011422411, 0.85853996031461433, 0.79065040650406504, datetime.timedelta(0, 427, 927862)]]\n",
    "[0.80310735939302502, 0.80134412203377714, 0.77542214632977435, 0.81534391534391537, 0.81697793752433112, 0.82194169531860661, 0.82153339873196618, 0.81766738578277387, 0.82211208035950312, 0.82702497937955, 0.82550831970847571, 0.81691409011422411]\n",
    "best perfomer: \n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 scores:\n",
    "\n",
    "0.803107359393 //\n",
    "0.801344122034 //\n",
    "0.77542214633 //\n",
    "0.815343915344 //\n",
    "0.816977937524 //\n",
    "0.821941695319 //\n",
    "0.821533398732 //\n",
    "0.817667385783 //\n",
    "0.82211208036 //\n",
    "0.82702497938 //\n",
    "0.825508319708 //\n",
    "0.816914090114 //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Tuned Random Forest Classifier, the best performer:\n",
    "\n",
    "['RandomForestClassifier', 0.827025, 0.853782, 0.813008, datetime.timedelta(0, 419, 267422)] \n",
    "\n",
    "F1 SCORE = 0.827025\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best params: criterion='entropy', max_features='auto', n_estimators=200\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original vs Under-Sampled\n",
    "\n",
    "The results certainly show that undersampling performs extremely well. However when we intuitively think about why this is so, it is perhaps not the wise approach. When under-sampling we have reduced the amount of information we have from over 200,000 real life examples (albeit benign transactions) and brought this down to merely <500. \n",
    "By doing this, as mentioned, we lose a *lot* of information that the classifier could learn from and hence become more generalisable. It is likely the case that we just overfit to the small dataset.\n",
    "\n",
    "To this end, it would appear that perhaps no sampling is better here. The original data performed fairly well across the board of classifiers, with precision being stronger as the majority. \n",
    "\n",
    "### Oversample vs SMOTE\n",
    "\n",
    "As seen, the results for Oversampling are marginally higher than that of SMOTE but due to the understanding of how the algorithms work and how we resample inside the cross validation loop, it is easy to understand why these results are likely to be biased.\n",
    "\n",
    "Oversampling simply duplicates datapoints randomly, so there is a lot of redundant data floating around. This means it is likely that during the CV process, the testing fold will likely contain duplicate data as in some of the training folds and therefore we have a 'leakage' of test data. This would explain why Oversampling appears to achieve better results.\n",
    "\n",
    "For this reason, taking the results of SMOTE is preferred, as it is more 'true'. This is because SMOTE uses K Nearest Neigbours to pick a nearby datapoint at random and then it randomly extrapolates this point in either the positive of negative direction by an amount in the range [0,1]. Effectively, this creates new data points which is a lot better to train on than duplicate information.\n",
    "\n",
    "### Original vs SMOTE\n",
    "\n",
    "The question then begs, is SMOTE worth it at all? Given that the original dataset achieves quite well in comparison. Well, it depends what we care about most. If we care about Recall and hence catching fraudluent transactions, then SMOTE has an advantage here. Taking the best achieving classifier, that is RandomForest, we can see that by using SMOTE we have a considerable margin on Recall, at the expense of some precision, but maintaining a marginally hgiher F1 score overall. So, by considering the classifier that appears to be suited for the problem at hand, SMOTE allows us to achieve higher than the original dataset.\n",
    "\n",
    "### Test_Train_Split vs Custom cross_val_score using KFold\n",
    "#### How a difference in splitting can influence results\n",
    "\n",
    "To represent the importance of ensuring all of the data is used to validate the model (using KFold), we look at the results of using test_train_split to split the data and then resampling the training data only (to preserve test data) and then averaging this n times. This variation in results show that we have to be careful in cross validating correctly in order to achieve the most true results.\n",
    "\n",
    "### Best classifier\n",
    "\n",
    "An overall majority classifier that appears to be most suited to this problem is the Random Forest Classifier. This classifier can maintain precision the best when resampling the data, to leave a respectable F1-score. Taking this classifier as the most suited and fine tuning it to try and squeeze the best possible result gave an F1 score of 0.827025, using SMOTE. This can be used as an estimate of the best value we can achieve from baseline work, for use in comparisons with later models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ''' Accounting properly for sampling in CV\n",
    " \n",
    " ORIGINAL\n",
    " ==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier\n",
    "LogisticRegression      0.679526   0.858680  0.585366 00:00:02.101358\n",
    "KNeighborsClassifier    0.773953   0.834210  0.733740 00:00:00.672486\n",
    "LinearSVC               0.702664   0.911093  0.609756 00:00:44.615623\n",
    "DecisionTreeClassifier  0.648748   0.584061  0.747967 00:00:12.705187\n",
    "RandomForestClassifier  0.789572   0.867006  0.737805 00:00:11.946860\n",
    "MLPClassifier           0.740725   0.789986  0.701220 00:00:10.611695\n",
    "GaussianNB              0.114077   0.061255  0.833333 00:00:00.110761\n",
    "==============================\n",
    "\n",
    "UNDER\n",
    "==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier\n",
    "LogisticRegression      0.920479   0.962354  0.882114 00:00:00.005487\n",
    "KNeighborsClassifier    0.929551   0.978015  0.886179 00:00:00.000986\n",
    "LinearSVC               0.908181   0.955016  0.865854 00:00:00.016134\n",
    "DecisionTreeClassifier  0.900284   0.910581  0.890244 00:00:00.009997\n",
    "RandomForestClassifier  0.915486   0.952169  0.882114 00:00:00.040110\n",
    "MLPClassifier           0.916529   0.956296  0.880081 00:00:00.545562\n",
    "GaussianNB              0.900877   0.965324  0.845528 00:00:00.001272\n",
    "==============================\n",
    "\n",
    "OVER\n",
    "==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier\n",
    "LogisticRegression      0.111893   0.059767  0.892276 00:00:03.679684\n",
    "KNeighborsClassifier    0.634392   0.563856  0.798780 00:00:01.675460\n",
    "LinearSVC               0.117779   0.063179  0.871951 00:01:19.514793\n",
    "DecisionTreeClassifier  0.649036   0.661330  0.664634 00:00:07.959666\n",
    "RandomForestClassifier  0.801992   0.884864  0.745935 00:00:10.799792\n",
    "MLPClassifier           0.658083   0.595006  0.774390 00:00:24.078549\n",
    "GaussianNB              0.100591   0.053461  0.855691 00:00:00.198887\n",
    "==============================\n",
    "\n",
    "SMOTE\n",
    "==============================\n",
    "Cross validation training results: \n",
    "                        F1 Score  Precision    Recall   Training Time\n",
    "Classifier\n",
    "LogisticRegression      0.106679   0.056839  0.884146 00:00:03.850433\n",
    "KNeighborsClassifier    0.500628   0.375985  0.831301 00:00:01.722399\n",
    "LinearSVC               0.116943   0.062724  0.867886 00:01:21.129306\n",
    "DecisionTreeClassifier  0.441011   0.325126  0.711382 00:00:23.395320\n",
    "RandomForestClassifier  0.806464   0.833590  0.794715 00:00:21.880070\n",
    "MLPClassifier           0.709039   0.708030  0.725610 00:00:24.371739\n",
    "GaussianNB              0.107311   0.057277  0.855691 00:00:00.193990\n",
    "==============================\n",
    " \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Naive averaging, using test_train_split only. \n",
    "    Oversampling training split and preserving test set, averaging over 3 runs\n",
    "    \n",
    "SUMMARY OF RESULTS (AVG over three random iterations)\n",
    "==============================\n",
    "Cross validation training results: \n",
    "               Classifier  F1 Score  Precision    Recall   Training Time\n",
    "0      LogisticRegression  0.711097   0.849243  0.612047 00:00:01.661159\n",
    "0    KNeighborsClassifier  0.846665   0.950516  0.763758 00:00:00.692843\n",
    "0               LinearSVC  0.798250   0.891613  0.723210 00:00:49.479348\n",
    "0  DecisionTreeClassifier  0.941819   0.954909  0.929109 00:00:09.491732\n",
    "0  RandomForestClassifier  0.932806   0.992030  0.880539 00:00:12.129519\n",
    "0           MLPClassifier  0.867500   0.963761  0.789322 00:00:10.706168\n",
    "0              GaussianNB  0.122036   0.065706  0.856953 00:00:00.100451\n",
    "==============================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Tuned Random Forest Classifier, the best performer:\n",
    "\n",
    "['RandomForestClassifier', 0.827025, 0.853782, 0.813008, datetime.timedelta(0, 419, 267422)] \n",
    "\n",
    "F1 SCORE = 0.827025\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
